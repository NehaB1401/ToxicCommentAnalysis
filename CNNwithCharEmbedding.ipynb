{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "To build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults and identity-based hate. The dataset used are comments from Wikipedia’s talk page edits.\n",
    "\n",
    "Google built a range of publicly available models served through the Perspective API, including toxicity. But the current models still make errors, and they don’t allow users to select which types of toxicity they’re interested in finding (e.g. some platforms may be fine with profanity, but not with other types of toxic content).\n",
    "\n",
    "We have extended our neural network model further to prove that this model is able to detect toxicity level and also rightly classify the toxicity level which is not provided by Google's Perspective API. Below is an example of an input test comment \"I will kill you\" and it has been rightly classified by this model as 95% threat.\n",
    "\n",
    "We then compared our model outputs with that of Google's Perspective API's model with various input sentences.\n",
    "\n",
    "We further intend on extending our model to run over twitter comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach\n",
    "\n",
    "The idea is to use the train dataset to train the models with the words in the comments as predictor variables and to predict the probability of toxicity level of a comment. A pre- trained model that gives the best accuracy to various user comments to combat the ongoing issue of online forum abuse. Our project is focused on developing a series of neural network models. The goal is to find the strengths and weakness of different Deep Learning models on the text classification task. We developed 3 specific Neural Network models for this project which are as follows:\n",
    "1. Convolution Neural Network (CNN with character-level embedding)\n",
    "2. Convolution Neural Network (CNN with word embedding)\n",
    "3. Recurrent Neural Network (RNN) with Long Short Term Memory (LSTM) cells\n",
    "We intend to test the above models trained with the Wikipedia data and word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification\n",
    "\n",
    "In this notebook, we'll be developing a Neural Network models that can classify string comments based on their toxicity:\n",
    "* `toxic`\n",
    "* `severe_toxic`\n",
    "* `obscene`\n",
    "* `threat`\n",
    "* `insult`\n",
    "* `identity_hate`\n",
    "\n",
    "This is a part of the [Toxic Comment Classification](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) Kaggle competition. From the site:\n",
    "\n",
    ">In this competition, you’re challenged to build a multi-headed model that’s capable of detecting different types of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models. You’ll be using a dataset of comments from Wikipedia’s talk page edits. Improvements to the current model will hopefully help online discussion become more productive and respectful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "The data we'll be using consists of a large number of Wikipedia comments which have been labeled by humans according to their relative toxicity. The data can be found here. Download the following and store in directory's data folder.\n",
    "\n",
    "    train.csv - the training set, contains comments with their binary labels.\n",
    "    test.csv - the test set, predict toxicity probabilities for these comments.\n",
    "    sample_submission.csv - the submission sample with the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function for ploting history of the model training\n",
    "from pyspark.sql import Row\n",
    "def plot_history(history_arg):\n",
    "  array = []\n",
    "  i =1\n",
    "  j =1\n",
    "  for acc in history_arg.history['acc']:\n",
    "    array.append(Row(epoch=i, accuracy=float(acc)))\n",
    "    i = i+1\n",
    "  acc_df = sqlContext.createDataFrame((array))\n",
    "\n",
    "  array = []\n",
    "  for loss in history_arg.history['loss']:\n",
    "      array.append(Row(epoch = j, loss = float(loss)))\n",
    "      j = j+1\n",
    "  loss_df = sqlContext.createDataFrame(array)\n",
    "\n",
    "  display_df = acc_df.join(loss_df,on=(\"epoch\")).orderBy(\"epoch\")\n",
    "  return display_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data\n",
    "Extract the features and labels and take a look at sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "#Class labels\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "#Read the data\n",
    "toxicWordsTrain = pd.read_csv(\"train.csv\");\n",
    "toxicWordsTest = pd.read_csv(\"test.csv\")\n",
    "\n",
    "y_train = toxicWordsTrain[list_classes].values\n",
    "x_train = toxicWordsTrain[\"comment_text\"]\n",
    "x_test  = toxicWordsTest[\"comment_text\"]\n",
    "\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data\n",
    "On analyzing the train data set, it was noted that the toxic levels in the comments are classified as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAGECAYAAADZSUEcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1542469df60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "colors_list = [\"brownish green\", \"pine green\", \"ugly purple\",\n",
    "               \"blood\", \"deep blue\", \"brown\", \"azure\"]\n",
    "\n",
    "palette= sns.xkcd_palette(colors_list)\n",
    "\n",
    "x=toxicWordsTrain.iloc[:,2:].sum()\n",
    "#print(x.index)\n",
    "plt.figure(figsize=(9,6))\n",
    "ax= sns.barplot(x.index, x.values,palette=palette)\n",
    "plt.title(\"Class\")\n",
    "plt.ylabel('Occurrences', fontsize=12)\n",
    "plt.xlabel('Type ')\n",
    "rects = ax.patches\n",
    "labels = x.values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 10, label, \n",
    "            ha='center', va='bottom')\n",
    "\n",
    "display(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment #1:  Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "Label #1:    [0 0 0 0 0 0]\n",
      "Comment #2:  D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
      "Label #2:    [0 0 0 0 0 0]\n",
      "Comment #3:  Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n",
      "Label #3:    [0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Sample from dataset\n",
    "for sample_i in range(3):\n",
    "    print('Comment #{}:  {}'.format(sample_i + 1, x_train[sample_i]))\n",
    "    print('Label #{}:    {}'.format(sample_i + 1, y_train[sample_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 159571/159571 [00:02<00:00, 58681.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10734904 words.\n",
      "532299 unique words.\n",
      "10 Most common words in the dataset:\n",
      "\"the\" \"to\" \"of\" \"and\" \"a\" \"I\" \"is\" \"you\" \"that\" \"in\"\n"
     ]
    }
   ],
   "source": [
    "# Explore vocabulary\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a counter object for each dataset\n",
    "word_counter = collections.Counter([word for sentence in tqdm(x_train, total=len(x_train)) \\\n",
    "                                                              for word in sentence.split()])\n",
    "\n",
    "print('{} words.'.format(len([word for sentence in x_train for word in sentence.split()])))\n",
    "print('{} unique words.'.format(len(word_counter)))\n",
    "print('10 Most common words in the dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*word_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 10,734,904 words, 532,299 of which are unique, and the 10 most common being: \"the\", \"to\", \"of\", \"and\", \"a\", \"I\", \"is\", \"you\", \"that\", and \"in\". One problem here is that we are counting uppercase words as different from lower case words and a bunch of other symbols that aren't really useful for our goal. A data cleanup will be done in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data\n",
    "We preprocess our data a bit so that it's in a format we can input into a neural network. The process includes:\n",
    "\n",
    "    1. Remove irrelevant characters (!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n).\n",
    "    2. Convert all letters to lowercase (HeLlO -> hello).\n",
    "    3. As this is character level embedding, Consider every character as a seperate token. \n",
    "    4. Tokenize our words (hi how are you -> [23, 1, 5, 13]).\n",
    "    5. Standaridize our input length with padding (hi how are you -> [23, 1, 5, 13, 0, 0, 0]).\n",
    "We can go further and consider combining misspelled, slang, or different word inflections into single base words. However, the benefit of using a neural network is that they do well with raw input, so we'll stick with what we have listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 2335\n",
      "Longest comment size: 5000\n",
      "Average comment size: 394.0732213246768\n",
      "Stdev of comment size: 590.7184309382144\n",
      "Max comment size: 2166\n",
      "\n",
      "Sequence 1\n",
      "  Input:  Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "  Output: [35, 48, 17, 11, 4, 7, 4, 3, 6, 5, 7, 26, 33, 10, 16, 1, 3, 10, 2, 1, 2, 12, 6, 3, 8, 1, 15, 4, 12, 2, 1, 13, 7, 12, 2, 9, 1, 15, 16, 1, 13, 8, 2, 9, 7, 4, 15, 2, 1, 39, 4, 9, 12, 14, 5, 9, 2, 1, 46, 2, 3, 4, 11, 11, 6, 14, 4, 1, 54, 4, 7, 1, 20, 2, 9, 2, 1, 9, 2, 24, 2, 9, 3, 2, 12, 56, 1, 29, 10, 2, 16, 1, 20, 2, 9, 2, 7, 30, 3, 1, 24, 4, 7, 12, 4, 11, 6, 8, 15, 8, 25, 1, 57, 13, 8, 3, 1, 14, 11, 5, 8, 13, 9, 2, 1, 5, 7, 1, 8, 5, 15, 2, 1, 58, 31, 8, 1, 4, 19, 3, 2, 9, 1, 27, 1, 24, 5, 3, 2, 12, 1, 4, 3, 1, 38, 2, 20, 1, 59, 5, 9, 23, 1, 50, 5, 11, 11, 8, 1, 54, 31, 34, 22, 1, 31, 7, 12, 1, 17, 11, 2, 4, 8, 2, 1, 12, 5, 7, 30, 3, 1, 9, 2, 15, 5, 24, 2, 1, 3, 10, 2, 1, 3, 2, 15, 17, 11, 4, 3, 2, 1, 19, 9, 5, 15, 1, 3, 10, 2, 1, 3, 4, 11, 23, 1, 17, 4, 18, 2, 1, 8, 6, 7, 14, 2, 1, 27, 30, 15, 1, 9, 2, 3, 6, 9, 2, 12, 1, 7, 5, 20, 22, 70, 64, 22, 52, 43, 67, 22, 65, 70, 22, 52, 72]\n",
      "Sequence 2\n",
      "  Input:  D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
      "  Output: [50, 30, 4, 20, 20, 40, 1, 39, 2, 1, 15, 4, 3, 14, 10, 2, 8, 1, 3, 10, 6, 8, 1, 21, 4, 14, 23, 18, 9, 5, 13, 7, 12, 1, 14, 5, 11, 5, 13, 9, 1, 27, 30, 15, 1, 8, 2, 2, 15, 6, 7, 18, 11, 16, 1, 8, 3, 13, 14, 23, 1, 20, 6, 3, 10, 22, 1, 29, 10, 4, 7, 23, 8, 22, 1, 1, 51, 3, 4, 11, 23, 47, 1, 52, 41, 45, 67, 41, 25, 1, 66, 4, 7, 13, 4, 9, 16, 1, 41, 41, 25, 1, 52, 43, 41, 71, 1, 51, 53, 29, 34, 47]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and Pad\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Create tokenizer\n",
    "tokenizer = Tokenizer(num_words=None,\n",
    "                      filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                      lower=True,\n",
    "                      split=\" \",\n",
    "                      char_level=True)\n",
    "\n",
    "# Fit and run tokenizer\n",
    "tokenizer.fit_on_texts(list(x_train))\n",
    "tokenized_train = tokenizer.texts_to_sequences(x_train)\n",
    "tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Extract variables\n",
    "vocab_size = len(word_index)\n",
    "print('Vocab size: {}'.format(vocab_size))\n",
    "longest = max(len(seq) for seq in tokenized_train)\n",
    "print(\"Longest comment size: {}\".format(longest))\n",
    "average = np.mean([len(seq) for seq in tokenized_train])\n",
    "print(\"Average comment size: {}\".format(average))\n",
    "stdev = np.std([len(seq) for seq in tokenized_train])\n",
    "print(\"Stdev of comment size: {}\".format(stdev))\n",
    "max_len = int(average + stdev * 3)\n",
    "print('Max comment size: {}'.format(max_len))\n",
    "print()\n",
    "\n",
    "# Pad sequences\n",
    "processed_X_train = pad_sequences(tokenized_train, maxlen=max_len, padding='post', truncating='post')\n",
    "processed_X_test = pad_sequences(tokenized_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Sample tokenization\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(x_train[:2], tokenized_train[:2])):\n",
    "    print('Sequence {}'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, our vocabulary size drops to a more manageable 210,337 with a max comment size of 371 words and an average comment size of about 68 words per sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "The data representation for our vocabulary is one-hot encoding where every word is transformed into a vector with a 1 in its corresponding location. For example, if our word vector is [hi, how, are, you] and the word we are looking at is \"you\", the input vector for \"you\" would just be [0, 0, 0, 1]. This works fine unless our vocabulary is huge - in this case, 210,000 - which means we would end up with word vectors that consist mainly of a bunch of 0s.\n",
    "\n",
    "Instead, we can use a Word2Vec technique to find continuous embeddings for our words. Here, we'll be using the pretrained FastText embeddings from Facebook to produce a 300-dimension vector for each word in our vocabulary.\n",
    "\n",
    "    P. Bojanowski, E. Grave, A. Joulin, T. Mikolov, Enriching Word Vectors with Subword Information\n",
    "The benefit of this continuous embedding is that words with similar predictive power will appear closer together on our word vector. The downside is that this creates more of a black box where the words with the most predictive power get lost in the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2519371 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 300\n",
    "\n",
    "# Get embeddings\n",
    "embeddings_index = {}\n",
    "f = open('wiki.en.vec', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.rstrip().rsplit(' ', embedding_dim)\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found {} word vectors.'.format(len(embeddings_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build embedding matrix\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is a lengthy process and hence saving the output to the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save embeddings\n",
    "import h5py\n",
    "with h5py.File('embeddings.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"fasttext\",  data=embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "with h5py.File('embeddings.h5', 'r') as hf:\n",
    "    embedding_matrix = hf['fasttext'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Convolution Neural Network(CNN) with character embeddings:\n",
    "\n",
    "\n",
    ">A character level model will use the character as the smallest entity. This can help in dealing with common misspellings, different permutations of words and languages that rely on the context for word conjugations. The model reads characters one by one, including spaces, and creates a one-hot embedding of the comment. The CNN model we used consist of a 1-dimensional convolutional layer across the concatenated character embeddings for each character in the input comment.\n",
    "\n",
    "\n",
    "Now that the data is preprocessed and our embeddings are ready, we can build a model. We will build a neural network architecture that is comprises of the following:\n",
    "\n",
    "    Embedding layer - word vector representations.\n",
    "    Convolutional layer - run multiple filters over that temporal data.\n",
    "    Fully connected layer - classify input based on filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nehab\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2166, 300)         700800    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2166, 128)         192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 722, 128)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 900,196\n",
      "Trainable params: 899,940\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras.backend\n",
    "from keras.models import Sequential\n",
    "from keras.layers import CuDNNGRU, Dense, Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout, GlobalMaxPooling1D, BatchNormalization\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "# Initate model\n",
    "model = Sequential()\n",
    "\n",
    "# Add Embedding layer\n",
    "model.add(Embedding(vocab_size + 1, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True))\n",
    "\n",
    "# Add Recurrent layers\n",
    "#model.add(Bidirectional(CuDNNGRU(300, return_sequences=True)))\n",
    "\n",
    "# Add Convolutional layer\n",
    "model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model\n",
    "We'll be using binary crossentropy as our loss function and clipping our gradients to avoid any explosions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "     return keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "lr = .0001\n",
    "model.compile(loss=loss, optimizer=Nadam(lr=lr, clipnorm=1.0),\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metric\n",
    "To evaluate our model, we'll be looking at its AUC ROC score (area under the receiver operating characteristic curve). We will be looking at the probability that our model ranks a randomly chosen positive instance higher than a randomly chosen negative one. With data that mostly consists of negative labels (no toxicity), our model could just learn to always predict negative and end up with a pretty high accuracy. AUC ROC helps correct this by putting more weight on the the positive examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After init\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, filepath, validation_data=(), interval=1, max_epoch = 100):\n",
    "        super(Callback, self).__init__()\n",
    "        # Initialize state variables\n",
    "        print(\"After init\")\n",
    "        self.interval = interval\n",
    "        self.filepath = filepath\n",
    "        self.stopped_epoch = max_epoch\n",
    "        self.best = 0\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.y_pred = np.zeros(self.y_val.shape)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        print(\"Epoch end 1\")\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict_proba(self.X_val, verbose=0)\n",
    "            current = roc_auc_score(self.y_val, y_pred)\n",
    "            logs['roc_auc_val'] = current\n",
    "\n",
    "            if current > self.best: #save model\n",
    "                print(\" - AUC - improved from {:.5f} to {:.5f}\".format(self.best, current))\n",
    "                self.best = current\n",
    "                self.y_pred = y_pred\n",
    "                self.stopped_epoch = epoch+1\n",
    "                self.model.save(self.filepath, overwrite=True)\n",
    "            else:\n",
    "                print(\" - AUC - did not improve\")\n",
    "            \n",
    "[X, X_val, y, y_val] = train_test_split(processed_X_train, y_train, test_size=0.03, shuffle=False)\n",
    "RocAuc = RocAucEvaluation(filepath='model.best.hdf5',validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Using a batch size of 64 and set the number of epochs as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 154783 samples, validate on 4788 samples\n",
      "Epoch 1/1\n",
      " 18496/154783 [==>...........................] - ETA: 6:26:48 - loss: 0.86 - ETA: 5:02:30 - loss: 0.88 - ETA: 4:25:14 - loss: 0.87 - ETA: 4:00:30 - loss: 0.86 - ETA: 3:45:30 - loss: 0.85 - ETA: 3:34:46 - loss: 0.83 - ETA: 3:26:33 - loss: 0.82 - ETA: 3:19:38 - loss: 0.80 - ETA: 3:16:21 - loss: 0.79 - ETA: 3:12:09 - loss: 0.78 - ETA: 3:08:48 - loss: 0.77 - ETA: 3:06:02 - loss: 0.75 - ETA: 3:03:33 - loss: 0.74 - ETA: 3:02:07 - loss: 0.73 - ETA: 3:00:21 - loss: 0.71 - ETA: 2:58:41 - loss: 0.70 - ETA: 2:57:04 - loss: 0.69 - ETA: 2:55:55 - loss: 0.68 - ETA: 2:54:42 - loss: 0.67 - ETA: 2:53:44 - loss: 0.66 - ETA: 2:52:41 - loss: 0.65 - ETA: 2:51:55 - loss: 0.65 - ETA: 2:51:02 - loss: 0.64 - ETA: 2:50:19 - loss: 0.63 - ETA: 2:49:35 - loss: 0.62 - ETA: 2:48:52 - loss: 0.61 - ETA: 2:48:13 - loss: 0.61 - ETA: 2:47:40 - loss: 0.60 - ETA: 2:47:03 - loss: 0.59 - ETA: 2:46:26 - loss: 0.58 - ETA: 2:45:54 - loss: 0.58 - ETA: 2:45:24 - loss: 0.57 - ETA: 2:44:54 - loss: 0.56 - ETA: 2:44:34 - loss: 0.56 - ETA: 2:44:12 - loss: 0.55 - ETA: 2:44:38 - loss: 0.54 - ETA: 2:44:41 - loss: 0.54 - ETA: 2:44:52 - loss: 0.54 - ETA: 2:44:56 - loss: 0.53 - ETA: 2:47:02 - loss: 0.53 - ETA: 2:47:47 - loss: 0.52 - ETA: 2:47:28 - loss: 0.52 - ETA: 2:47:02 - loss: 0.51 - ETA: 2:46:37 - loss: 0.50 - ETA: 2:46:11 - loss: 0.50 - ETA: 2:45:48 - loss: 0.50 - ETA: 2:45:23 - loss: 0.49 - ETA: 2:44:56 - loss: 0.49 - ETA: 2:44:30 - loss: 0.48 - ETA: 2:44:09 - loss: 0.48 - ETA: 2:43:44 - loss: 0.47 - ETA: 2:43:21 - loss: 0.47 - ETA: 2:42:58 - loss: 0.46 - ETA: 2:42:37 - loss: 0.46 - ETA: 2:42:16 - loss: 0.46 - ETA: 2:41:53 - loss: 0.45 - ETA: 2:41:35 - loss: 0.45 - ETA: 2:41:59 - loss: 0.45 - ETA: 2:42:15 - loss: 0.44 - ETA: 2:41:58 - loss: 0.44 - ETA: 2:41:45 - loss: 0.43 - ETA: 2:41:30 - loss: 0.43 - ETA: 2:41:13 - loss: 0.43 - ETA: 2:41:01 - loss: 0.42 - ETA: 2:40:45 - loss: 0.42 - ETA: 2:40:28 - loss: 0.42 - ETA: 2:40:10 - loss: 0.42 - ETA: 2:39:54 - loss: 0.41 - ETA: 2:39:37 - loss: 0.41 - ETA: 2:39:28 - loss: 0.41 - ETA: 2:39:12 - loss: 0.41 - ETA: 2:38:58 - loss: 0.40 - ETA: 2:38:45 - loss: 0.40 - ETA: 2:38:34 - loss: 0.40 - ETA: 2:38:22 - loss: 0.39 - ETA: 2:38:13 - loss: 0.39 - ETA: 2:38:01 - loss: 0.39 - ETA: 2:38:10 - loss: 0.39 - ETA: 2:39:00 - loss: 0.38 - ETA: 2:39:15 - loss: 0.38 - ETA: 2:39:28 - loss: 0.38 - ETA: 2:39:33 - loss: 0.38 - ETA: 2:39:43 - loss: 0.37 - ETA: 2:39:48 - loss: 0.37 - ETA: 2:39:35 - loss: 0.37 - ETA: 2:39:21 - loss: 0.37 - ETA: 2:39:09 - loss: 0.36 - ETA: 2:38:59 - loss: 0.36 - ETA: 2:38:46 - loss: 0.36 - ETA: 2:38:33 - loss: 0.36 - ETA: 2:38:20 - loss: 0.36 - ETA: 2:38:08 - loss: 0.36 - ETA: 2:37:55 - loss: 0.35 - ETA: 2:37:44 - loss: 0.35 - ETA: 2:37:34 - loss: 0.35 - ETA: 2:37:24 - loss: 0.35 - ETA: 2:37:14 - loss: 0.35 - ETA: 2:37:02 - loss: 0.35 - ETA: 2:36:50 - loss: 0.34 - ETA: 2:36:41 - loss: 0.34 - ETA: 2:36:32 - loss: 0.34 - ETA: 2:36:22 - loss: 0.34 - ETA: 2:36:10 - loss: 0.34 - ETA: 2:36:00 - loss: 0.33 - ETA: 2:35:52 - loss: 0.33 - ETA: 2:35:41 - loss: 0.33 - ETA: 2:35:30 - loss: 0.33 - ETA: 2:35:21 - loss: 0.33 - ETA: 2:35:12 - loss: 0.33 - ETA: 2:35:01 - loss: 0.32 - ETA: 2:34:50 - loss: 0.32 - ETA: 2:34:45 - loss: 0.32 - ETA: 2:34:42 - loss: 0.32 - ETA: 2:34:42 - loss: 0.32 - ETA: 2:34:39 - loss: 0.32 - ETA: 2:34:31 - loss: 0.32 - ETA: 2:34:22 - loss: 0.31 - ETA: 2:34:14 - loss: 0.31 - ETA: 2:34:06 - loss: 0.31 - ETA: 2:34:00 - loss: 0.31 - ETA: 2:33:55 - loss: 0.31 - ETA: 2:33:51 - loss: 0.31 - ETA: 2:33:41 - loss: 0.31 - ETA: 2:33:31 - loss: 0.30 - ETA: 2:33:22 - loss: 0.30 - ETA: 2:33:13 - loss: 0.30 - ETA: 2:33:07 - loss: 0.30 - ETA: 2:33:01 - loss: 0.30 - ETA: 2:32:52 - loss: 0.30 - ETA: 2:32:50 - loss: 0.30 - ETA: 2:32:46 - loss: 0.29 - ETA: 2:32:37 - loss: 0.29 - ETA: 2:32:30 - loss: 0.29 - ETA: 2:32:21 - loss: 0.29 - ETA: 2:32:19 - loss: 0.29 - ETA: 2:32:10 - loss: 0.29 - ETA: 2:32:08 - loss: 0.29 - ETA: 2:32:01 - loss: 0.29 - ETA: 2:31:53 - loss: 0.29 - ETA: 2:31:48 - loss: 0.28 - ETA: 2:31:42 - loss: 0.28 - ETA: 2:31:35 - loss: 0.28 - ETA: 2:31:33 - loss: 0.28 - ETA: 2:31:28 - loss: 0.28 - ETA: 2:31:22 - loss: 0.28 - ETA: 2:31:20 - loss: 0.28 - ETA: 2:31:15 - loss: 0.28 - ETA: 2:31:09 - loss: 0.28 - ETA: 2:31:04 - loss: 0.28 - ETA: 2:31:03 - loss: 0.27 - ETA: 2:30:57 - loss: 0.27 - ETA: 2:30:51 - loss: 0.27 - ETA: 2:30:47 - loss: 0.27 - ETA: 2:30:45 - loss: 0.27 - ETA: 2:30:40 - loss: 0.27 - ETA: 2:30:31 - loss: 0.27 - ETA: 2:30:30 - loss: 0.27 - ETA: 2:30:24 - loss: 0.27 - ETA: 2:30:19 - loss: 0.27 - ETA: 2:30:15 - loss: 0.26 - ETA: 2:30:14 - loss: 0.26 - ETA: 2:30:09 - loss: 0.26 - ETA: 2:30:08 - loss: 0.26 - ETA: 2:30:01 - loss: 0.26 - ETA: 2:30:00 - loss: 0.26 - ETA: 2:29:52 - loss: 0.26 - ETA: 2:29:45 - loss: 0.26 - ETA: 2:29:39 - loss: 0.26 - ETA: 2:29:31 - loss: 0.26 - ETA: 2:29:23 - loss: 0.26 - ETA: 2:29:16 - loss: 0.26 - ETA: 2:29:10 - loss: 0.26 - ETA: 2:29:03 - loss: 0.25 - ETA: 2:28:56 - loss: 0.25 - ETA: 2:28:49 - loss: 0.25 - ETA: 2:28:42 - loss: 0.25 - ETA: 2:28:35 - loss: 0.25 - ETA: 2:28:29 - loss: 0.25 - ETA: 2:28:23 - loss: 0.25 - ETA: 2:28:17 - loss: 0.25 - ETA: 2:28:11 - loss: 0.25 - ETA: 2:28:04 - loss: 0.25 - ETA: 2:27:57 - loss: 0.25 - ETA: 2:27:50 - loss: 0.24 - ETA: 2:27:43 - loss: 0.24 - ETA: 2:27:36 - loss: 0.24 - ETA: 2:27:29 - loss: 0.24 - ETA: 2:27:23 - loss: 0.24 - ETA: 2:27:16 - loss: 0.24 - ETA: 2:27:09 - loss: 0.24 - ETA: 2:27:01 - loss: 0.24 - ETA: 2:26:55 - loss: 0.24 - ETA: 2:26:48 - loss: 0.24 - ETA: 2:26:43 - loss: 0.24 - ETA: 2:26:36 - loss: 0.24 - ETA: 2:26:30 - loss: 0.24 - ETA: 2:26:23 - loss: 0.24 - ETA: 2:26:17 - loss: 0.24 - ETA: 2:26:10 - loss: 0.23 - ETA: 2:26:04 - loss: 0.23 - ETA: 2:25:57 - loss: 0.23 - ETA: 2:25:52 - loss: 0.23 - ETA: 2:25:52 - loss: 0.23 - ETA: 2:25:52 - loss: 0.23 - ETA: 2:25:49 - loss: 0.23 - ETA: 2:25:42 - loss: 0.23 - ETA: 2:25:36 - loss: 0.23 - ETA: 2:25:29 - loss: 0.23 - ETA: 2:25:22 - loss: 0.23 - ETA: 2:25:16 - loss: 0.23 - ETA: 2:25:09 - loss: 0.23 - ETA: 2:25:03 - loss: 0.23 - ETA: 2:24:56 - loss: 0.23 - ETA: 2:24:50 - loss: 0.23 - ETA: 2:24:44 - loss: 0.23 - ETA: 2:24:38 - loss: 0.22 - ETA: 2:24:34 - loss: 0.22 - ETA: 2:24:27 - loss: 0.22 - ETA: 2:24:20 - loss: 0.22 - ETA: 2:24:14 - loss: 0.22 - ETA: 2:24:09 - loss: 0.22 - ETA: 2:24:06 - loss: 0.22 - ETA: 2:24:04 - loss: 0.22 - ETA: 2:24:01 - loss: 0.22 - ETA: 2:23:56 - loss: 0.22 - ETA: 2:23:49 - loss: 0.22 - ETA: 2:23:43 - loss: 0.22 - ETA: 2:23:36 - loss: 0.22 - ETA: 2:23:30 - loss: 0.22 - ETA: 2:23:24 - loss: 0.22 - ETA: 2:23:17 - loss: 0.22 - ETA: 2:23:11 - loss: 0.22 - ETA: 2:23:05 - loss: 0.22 - ETA: 2:22:59 - loss: 0.22 - ETA: 2:22:53 - loss: 0.22 - ETA: 2:22:47 - loss: 0.22 - ETA: 2:22:42 - loss: 0.22 - ETA: 2:22:35 - loss: 0.22 - ETA: 2:22:29 - loss: 0.21 - ETA: 2:22:24 - loss: 0.21 - ETA: 2:22:19 - loss: 0.21 - ETA: 2:22:12 - loss: 0.21 - ETA: 2:22:06 - loss: 0.21 - ETA: 2:22:01 - loss: 0.21 - ETA: 2:21:55 - loss: 0.21 - ETA: 2:21:50 - loss: 0.21 - ETA: 2:21:46 - loss: 0.21 - ETA: 2:21:40 - loss: 0.21 - ETA: 2:21:34 - loss: 0.21 - ETA: 2:21:28 - loss: 0.21 - ETA: 2:21:22 - loss: 0.21 - ETA: 2:21:17 - loss: 0.21 - ETA: 2:21:11 - loss: 0.21 - ETA: 2:21:06 - loss: 0.21 - ETA: 2:21:00 - loss: 0.21 - ETA: 2:20:54 - loss: 0.21 - ETA: 2:20:49 - loss: 0.21 - ETA: 2:20:44 - loss: 0.21 - ETA: 2:20:38 - loss: 0.21 - ETA: 2:20:33 - loss: 0.21 - ETA: 2:20:27 - loss: 0.21 - ETA: 2:20:22 - loss: 0.21 - ETA: 2:20:17 - loss: 0.21 - ETA: 2:20:11 - loss: 0.20 - ETA: 2:20:06 - loss: 0.20 - ETA: 2:20:00 - loss: 0.20 - ETA: 2:19:55 - loss: 0.20 - ETA: 2:19:51 - loss: 0.20 - ETA: 2:19:51 - loss: 0.20 - ETA: 2:19:46 - loss: 0.20 - ETA: 2:19:41 - loss: 0.20 - ETA: 2:19:35 - loss: 0.20 - ETA: 2:19:30 - loss: 0.20 - ETA: 2:19:25 - loss: 0.20 - ETA: 2:19:19 - loss: 0.20 - ETA: 2:19:14 - loss: 0.20 - ETA: 2:19:09 - loss: 0.20 - ETA: 2:19:04 - loss: 0.20 - ETA: 2:18:58 - loss: 0.20 - ETA: 2:18:53 - loss: 0.20 - ETA: 2:18:48 - loss: 0.20 - ETA: 2:18:42 - loss: 0.20 - ETA: 2:18:38 - loss: 0.20 - ETA: 2:18:33 - loss: 0.20 - ETA: 2:18:27 - loss: 0.20 - ETA: 2:18:21 - loss: 0.20 - ETA: 2:18:16 - loss: 0.20 - ETA: 2:18:11 - loss: 0.20 - ETA: 2:18:07 - loss: 0.2029\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37120/154783 [======>.......................] - ETA: 2:18:01 - loss: 0.20 - ETA: 2:17:56 - loss: 0.20 - ETA: 2:17:51 - loss: 0.20 - ETA: 2:17:46 - loss: 0.20 - ETA: 2:17:41 - loss: 0.20 - ETA: 2:17:37 - loss: 0.20 - ETA: 2:17:33 - loss: 0.20 - ETA: 2:17:28 - loss: 0.20 - ETA: 2:17:23 - loss: 0.20 - ETA: 2:17:18 - loss: 0.19 - ETA: 2:17:13 - loss: 0.19 - ETA: 2:17:08 - loss: 0.19 - ETA: 2:17:04 - loss: 0.19 - ETA: 2:16:59 - loss: 0.19 - ETA: 2:16:54 - loss: 0.19 - ETA: 2:16:49 - loss: 0.19 - ETA: 2:16:46 - loss: 0.19 - ETA: 2:16:41 - loss: 0.19 - ETA: 2:16:37 - loss: 0.19 - ETA: 2:16:32 - loss: 0.19 - ETA: 2:16:28 - loss: 0.19 - ETA: 2:16:23 - loss: 0.19 - ETA: 2:16:18 - loss: 0.19 - ETA: 2:16:13 - loss: 0.19 - ETA: 2:16:09 - loss: 0.19 - ETA: 2:16:04 - loss: 0.19 - ETA: 2:16:00 - loss: 0.19 - ETA: 2:15:54 - loss: 0.19 - ETA: 2:15:49 - loss: 0.19 - ETA: 2:15:44 - loss: 0.19 - ETA: 2:15:39 - loss: 0.19 - ETA: 2:15:33 - loss: 0.19 - ETA: 2:15:29 - loss: 0.19 - ETA: 2:15:24 - loss: 0.19 - ETA: 2:15:18 - loss: 0.19 - ETA: 2:15:14 - loss: 0.19 - ETA: 2:15:09 - loss: 0.19 - ETA: 2:15:05 - loss: 0.19 - ETA: 2:15:01 - loss: 0.19 - ETA: 2:14:56 - loss: 0.19 - ETA: 2:14:51 - loss: 0.18 - ETA: 2:14:46 - loss: 0.18 - ETA: 2:14:41 - loss: 0.18 - ETA: 2:14:37 - loss: 0.18 - ETA: 2:14:32 - loss: 0.18 - ETA: 2:14:27 - loss: 0.18 - ETA: 2:14:23 - loss: 0.18 - ETA: 2:14:18 - loss: 0.18 - ETA: 2:14:14 - loss: 0.18 - ETA: 2:14:10 - loss: 0.18 - ETA: 2:14:10 - loss: 0.18 - ETA: 2:14:07 - loss: 0.18 - ETA: 2:14:03 - loss: 0.18 - ETA: 2:13:58 - loss: 0.18 - ETA: 2:13:54 - loss: 0.18 - ETA: 2:13:50 - loss: 0.18 - ETA: 2:13:46 - loss: 0.18 - ETA: 2:13:41 - loss: 0.18 - ETA: 2:13:37 - loss: 0.18 - ETA: 2:13:33 - loss: 0.18 - ETA: 2:13:29 - loss: 0.18 - ETA: 2:13:26 - loss: 0.18 - ETA: 2:13:22 - loss: 0.18 - ETA: 2:13:17 - loss: 0.18 - ETA: 2:13:13 - loss: 0.18 - ETA: 2:13:08 - loss: 0.18 - ETA: 2:13:04 - loss: 0.18 - ETA: 2:12:59 - loss: 0.18 - ETA: 2:12:54 - loss: 0.18 - ETA: 2:12:49 - loss: 0.18 - ETA: 2:12:45 - loss: 0.18 - ETA: 2:12:40 - loss: 0.18 - ETA: 2:12:36 - loss: 0.18 - ETA: 2:12:31 - loss: 0.18 - ETA: 2:12:26 - loss: 0.18 - ETA: 2:12:22 - loss: 0.18 - ETA: 2:12:18 - loss: 0.18 - ETA: 2:12:13 - loss: 0.18 - ETA: 2:12:09 - loss: 0.17 - ETA: 2:12:04 - loss: 0.17 - ETA: 2:12:00 - loss: 0.17 - ETA: 2:11:55 - loss: 0.17 - ETA: 2:11:50 - loss: 0.17 - ETA: 2:11:45 - loss: 0.17 - ETA: 2:11:41 - loss: 0.17 - ETA: 2:11:36 - loss: 0.17 - ETA: 2:11:32 - loss: 0.17 - ETA: 2:11:27 - loss: 0.17 - ETA: 2:11:23 - loss: 0.17 - ETA: 2:11:19 - loss: 0.17 - ETA: 2:11:15 - loss: 0.17 - ETA: 2:11:10 - loss: 0.17 - ETA: 2:11:06 - loss: 0.17 - ETA: 2:11:02 - loss: 0.17 - ETA: 2:10:57 - loss: 0.17 - ETA: 2:10:53 - loss: 0.17 - ETA: 2:10:48 - loss: 0.17 - ETA: 2:10:44 - loss: 0.17 - ETA: 2:10:39 - loss: 0.17 - ETA: 2:10:35 - loss: 0.17 - ETA: 2:10:31 - loss: 0.17 - ETA: 2:10:27 - loss: 0.17 - ETA: 2:10:24 - loss: 0.17 - ETA: 2:10:19 - loss: 0.17 - ETA: 2:10:15 - loss: 0.17 - ETA: 2:10:11 - loss: 0.17 - ETA: 2:10:06 - loss: 0.17 - ETA: 2:10:02 - loss: 0.17 - ETA: 2:09:57 - loss: 0.17 - ETA: 2:09:53 - loss: 0.17 - ETA: 2:09:48 - loss: 0.17 - ETA: 2:09:44 - loss: 0.17 - ETA: 2:09:39 - loss: 0.17 - ETA: 2:09:35 - loss: 0.17 - ETA: 2:09:31 - loss: 0.17 - ETA: 2:09:27 - loss: 0.17 - ETA: 2:09:22 - loss: 0.17 - ETA: 2:09:18 - loss: 0.17 - ETA: 2:09:15 - loss: 0.17 - ETA: 2:09:13 - loss: 0.17 - ETA: 2:09:11 - loss: 0.17 - ETA: 2:09:09 - loss: 0.17 - ETA: 2:09:07 - loss: 0.17 - ETA: 2:09:05 - loss: 0.16 - ETA: 2:09:02 - loss: 0.16 - ETA: 2:09:00 - loss: 0.16 - ETA: 2:08:59 - loss: 0.16 - ETA: 2:08:54 - loss: 0.16 - ETA: 2:08:50 - loss: 0.16 - ETA: 2:08:45 - loss: 0.16 - ETA: 2:08:40 - loss: 0.16 - ETA: 2:08:36 - loss: 0.16 - ETA: 2:08:32 - loss: 0.16 - ETA: 2:08:27 - loss: 0.16 - ETA: 2:08:23 - loss: 0.16 - ETA: 2:08:19 - loss: 0.16 - ETA: 2:08:15 - loss: 0.16 - ETA: 2:08:11 - loss: 0.16 - ETA: 2:08:07 - loss: 0.16 - ETA: 2:08:03 - loss: 0.16 - ETA: 2:07:58 - loss: 0.16 - ETA: 2:07:54 - loss: 0.16 - ETA: 2:07:50 - loss: 0.16 - ETA: 2:07:46 - loss: 0.16 - ETA: 2:07:42 - loss: 0.16 - ETA: 2:07:38 - loss: 0.16 - ETA: 2:07:34 - loss: 0.16 - ETA: 2:07:30 - loss: 0.16 - ETA: 2:07:25 - loss: 0.16 - ETA: 2:07:21 - loss: 0.16 - ETA: 2:07:18 - loss: 0.16 - ETA: 2:07:13 - loss: 0.16 - ETA: 2:07:09 - loss: 0.16 - ETA: 2:07:05 - loss: 0.16 - ETA: 2:07:01 - loss: 0.16 - ETA: 2:06:57 - loss: 0.16 - ETA: 2:06:53 - loss: 0.16 - ETA: 2:06:49 - loss: 0.16 - ETA: 2:06:45 - loss: 0.16 - ETA: 2:06:41 - loss: 0.16 - ETA: 2:06:37 - loss: 0.16 - ETA: 2:06:33 - loss: 0.16 - ETA: 2:06:29 - loss: 0.16 - ETA: 2:06:26 - loss: 0.16 - ETA: 2:06:22 - loss: 0.16 - ETA: 2:06:17 - loss: 0.16 - ETA: 2:06:13 - loss: 0.16 - ETA: 2:06:08 - loss: 0.16 - ETA: 2:06:04 - loss: 0.16 - ETA: 2:05:59 - loss: 0.16 - ETA: 2:05:56 - loss: 0.16 - ETA: 2:05:51 - loss: 0.16 - ETA: 2:05:47 - loss: 0.16 - ETA: 2:05:42 - loss: 0.16 - ETA: 2:05:38 - loss: 0.16 - ETA: 2:05:33 - loss: 0.16 - ETA: 2:05:29 - loss: 0.16 - ETA: 2:05:25 - loss: 0.16 - ETA: 2:05:22 - loss: 0.16 - ETA: 2:05:18 - loss: 0.16 - ETA: 2:05:14 - loss: 0.16 - ETA: 2:05:09 - loss: 0.16 - ETA: 2:05:05 - loss: 0.16 - ETA: 2:05:01 - loss: 0.16 - ETA: 2:04:57 - loss: 0.16 - ETA: 2:04:53 - loss: 0.16 - ETA: 2:04:49 - loss: 0.16 - ETA: 2:04:45 - loss: 0.16 - ETA: 2:04:40 - loss: 0.15 - ETA: 2:04:36 - loss: 0.15 - ETA: 2:04:32 - loss: 0.15 - ETA: 2:04:28 - loss: 0.15 - ETA: 2:04:24 - loss: 0.15 - ETA: 2:04:26 - loss: 0.15 - ETA: 2:04:31 - loss: 0.15 - ETA: 2:04:33 - loss: 0.15 - ETA: 2:04:36 - loss: 0.15 - ETA: 2:04:36 - loss: 0.15 - ETA: 2:04:40 - loss: 0.15 - ETA: 2:04:40 - loss: 0.15 - ETA: 2:04:40 - loss: 0.15 - ETA: 2:04:40 - loss: 0.15 - ETA: 2:04:41 - loss: 0.15 - ETA: 2:04:42 - loss: 0.15 - ETA: 2:04:43 - loss: 0.15 - ETA: 2:04:43 - loss: 0.15 - ETA: 2:04:42 - loss: 0.15 - ETA: 2:04:39 - loss: 0.15 - ETA: 2:04:34 - loss: 0.15 - ETA: 2:04:30 - loss: 0.15 - ETA: 2:04:28 - loss: 0.15 - ETA: 2:04:26 - loss: 0.15 - ETA: 2:04:25 - loss: 0.15 - ETA: 2:04:23 - loss: 0.15 - ETA: 2:04:22 - loss: 0.15 - ETA: 2:04:20 - loss: 0.15 - ETA: 2:04:19 - loss: 0.15 - ETA: 2:04:17 - loss: 0.15 - ETA: 2:04:15 - loss: 0.15 - ETA: 2:04:13 - loss: 0.15 - ETA: 2:04:11 - loss: 0.15 - ETA: 2:04:10 - loss: 0.15 - ETA: 2:04:08 - loss: 0.15 - ETA: 2:04:05 - loss: 0.15 - ETA: 2:04:06 - loss: 0.15 - ETA: 2:04:04 - loss: 0.15 - ETA: 2:04:02 - loss: 0.15 - ETA: 2:04:00 - loss: 0.15 - ETA: 2:03:57 - loss: 0.15 - ETA: 2:03:55 - loss: 0.15 - ETA: 4:31:40 - loss: 0.15 - ETA: 4:31:28 - loss: 0.15 - ETA: 4:31:13 - loss: 0.15 - ETA: 4:30:51 - loss: 0.15 - ETA: 4:30:31 - loss: 0.15 - ETA: 4:30:13 - loss: 0.15 - ETA: 4:29:55 - loss: 0.15 - ETA: 4:29:35 - loss: 0.15 - ETA: 4:29:16 - loss: 0.15 - ETA: 4:28:54 - loss: 0.15 - ETA: 4:28:29 - loss: 0.15 - ETA: 4:28:07 - loss: 0.15 - ETA: 4:27:43 - loss: 0.15 - ETA: 4:27:20 - loss: 0.15 - ETA: 4:26:57 - loss: 0.15 - ETA: 4:26:34 - loss: 0.15 - ETA: 4:26:11 - loss: 0.15 - ETA: 4:25:48 - loss: 0.15 - ETA: 4:25:25 - loss: 0.15 - ETA: 4:25:02 - loss: 0.15 - ETA: 4:24:40 - loss: 0.15 - ETA: 4:24:17 - loss: 0.15 - ETA: 4:23:54 - loss: 0.15 - ETA: 4:23:31 - loss: 0.15 - ETA: 4:23:14 - loss: 0.15 - ETA: 4:22:59 - loss: 0.15 - ETA: 4:22:46 - loss: 0.15 - ETA: 4:22:28 - loss: 0.14 - ETA: 4:22:06 - loss: 0.14 - ETA: 4:21:44 - loss: 0.14 - ETA: 4:21:22 - loss: 0.14 - ETA: 4:21:02 - loss: 0.14 - ETA: 4:20:41 - loss: 0.14 - ETA: 4:20:19 - loss: 0.14 - ETA: 4:19:57 - loss: 0.14 - ETA: 4:19:35 - loss: 0.14 - ETA: 4:19:13 - loss: 0.14 - ETA: 4:18:52 - loss: 0.14 - ETA: 4:18:31 - loss: 0.14 - ETA: 4:18:09 - loss: 0.14 - ETA: 4:17:47 - loss: 0.14 - ETA: 4:17:26 - loss: 0.14 - ETA: 4:17:05 - loss: 0.14 - ETA: 4:16:43 - loss: 0.14 - ETA: 4:16:22 - loss: 0.14 - ETA: 4:16:01 - loss: 0.14 - ETA: 4:15:40 - loss: 0.14 - ETA: 4:15:20 - loss: 0.14 - ETA: 4:14:59 - loss: 0.14 - ETA: 4:14:41 - loss: 0.14 - ETA: 4:14:20 - loss: 0.14 - ETA: 4:14:08 - loss: 0.14 - ETA: 4:13:55 - loss: 0.14 - ETA: 4:13:35 - loss: 0.14 - ETA: 4:13:15 - loss: 0.14 - ETA: 4:12:55 - loss: 0.14 - ETA: 4:12:35 - loss: 0.14 - ETA: 4:12:15 - loss: 0.14 - ETA: 4:11:55 - loss: 0.14 - ETA: 4:11:36 - loss: 0.14 - ETA: 4:11:18 - loss: 0.1465 55744/154783 [=========>....................] - ETA: 4:11:02 - loss: 0.14 - ETA: 4:10:51 - loss: 0.14 - ETA: 4:10:32 - loss: 0.14 - ETA: 4:10:14 - loss: 0.14 - ETA: 4:09:57 - loss: 0.14 - ETA: 4:09:38 - loss: 0.14 - ETA: 4:09:18 - loss: 0.14 - ETA: 4:08:58 - loss: 0.14 - ETA: 4:08:39 - loss: 0.14 - ETA: 4:08:19 - loss: 0.14 - ETA: 4:07:59 - loss: 0.14 - ETA: 4:07:40 - loss: 0.14 - ETA: 4:07:20 - loss: 0.14 - ETA: 4:07:01 - loss: 0.14 - ETA: 4:06:41 - loss: 0.14 - ETA: 4:06:22 - loss: 0.14 - ETA: 4:06:07 - loss: 0.14 - ETA: 4:05:49 - loss: 0.14 - ETA: 4:05:31 - loss: 0.14 - ETA: 4:05:11 - loss: 0.14 - ETA: 4:04:52 - loss: 0.14 - ETA: 4:04:32 - loss: 0.14 - ETA: 4:04:13 - loss: 0.14 - ETA: 4:03:54 - loss: 0.14 - ETA: 4:03:34 - loss: 0.14 - ETA: 4:03:15 - loss: 0.14 - ETA: 4:02:56 - loss: 0.14 - ETA: 4:02:37 - loss: 0.14 - ETA: 4:02:19 - loss: 0.14 - ETA: 4:02:00 - loss: 0.14 - ETA: 4:01:41 - loss: 0.14 - ETA: 4:01:23 - loss: 0.14 - ETA: 4:01:06 - loss: 0.14 - ETA: 4:00:48 - loss: 0.14 - ETA: 4:00:30 - loss: 0.14 - ETA: 4:00:11 - loss: 0.14 - ETA: 3:59:53 - loss: 0.14 - ETA: 3:59:34 - loss: 0.14 - ETA: 3:59:16 - loss: 0.14 - ETA: 3:58:57 - loss: 0.14 - ETA: 3:58:39 - loss: 0.14 - ETA: 3:58:21 - loss: 0.14 - ETA: 3:58:03 - loss: 0.14 - ETA: 3:57:45 - loss: 0.14 - ETA: 3:57:27 - loss: 0.14 - ETA: 3:57:08 - loss: 0.14 - ETA: 3:56:50 - loss: 0.14 - ETA: 3:56:32 - loss: 0.14 - ETA: 3:56:14 - loss: 0.14 - ETA: 3:55:56 - loss: 0.14 - ETA: 3:55:38 - loss: 0.14 - ETA: 3:55:20 - loss: 0.14 - ETA: 3:55:02 - loss: 0.14 - ETA: 3:54:44 - loss: 0.14 - ETA: 3:54:26 - loss: 0.14 - ETA: 3:54:08 - loss: 0.14 - ETA: 3:53:50 - loss: 0.14 - ETA: 3:53:33 - loss: 0.14 - ETA: 3:53:15 - loss: 0.14 - ETA: 3:52:57 - loss: 0.14 - ETA: 3:52:40 - loss: 0.14 - ETA: 3:52:22 - loss: 0.14 - ETA: 3:52:05 - loss: 0.14 - ETA: 3:51:47 - loss: 0.13 - ETA: 3:51:30 - loss: 0.13 - ETA: 3:51:14 - loss: 0.13 - ETA: 3:51:06 - loss: 0.13 - ETA: 3:51:00 - loss: 0.13 - ETA: 3:50:48 - loss: 0.13 - ETA: 3:50:31 - loss: 0.13 - ETA: 3:50:14 - loss: 0.13 - ETA: 3:49:57 - loss: 0.13 - ETA: 3:49:40 - loss: 0.13 - ETA: 3:49:25 - loss: 0.13 - ETA: 3:49:09 - loss: 0.13 - ETA: 3:48:54 - loss: 0.13 - ETA: 3:48:37 - loss: 0.13 - ETA: 3:48:23 - loss: 0.13 - ETA: 3:48:09 - loss: 0.13 - ETA: 3:47:55 - loss: 0.13 - ETA: 3:47:39 - loss: 0.13 - ETA: 3:47:22 - loss: 0.13 - ETA: 3:47:08 - loss: 0.13 - ETA: 3:46:52 - loss: 0.13 - ETA: 3:46:42 - loss: 0.13 - ETA: 3:46:33 - loss: 0.13 - ETA: 3:46:23 - loss: 0.13 - ETA: 3:46:13 - loss: 0.13 - ETA: 3:46:05 - loss: 0.13 - ETA: 3:45:57 - loss: 0.13 - ETA: 3:45:41 - loss: 0.13 - ETA: 3:45:25 - loss: 0.13 - ETA: 3:45:09 - loss: 0.13 - ETA: 3:44:53 - loss: 0.13 - ETA: 3:44:37 - loss: 0.13 - ETA: 3:44:23 - loss: 0.13 - ETA: 3:44:08 - loss: 0.13 - ETA: 3:43:53 - loss: 0.13 - ETA: 3:43:38 - loss: 0.13 - ETA: 3:43:23 - loss: 0.13 - ETA: 3:43:08 - loss: 0.13 - ETA: 3:42:53 - loss: 0.13 - ETA: 3:42:38 - loss: 0.13 - ETA: 3:42:23 - loss: 0.13 - ETA: 3:42:10 - loss: 0.13 - ETA: 3:41:56 - loss: 0.13 - ETA: 3:41:41 - loss: 0.13 - ETA: 3:41:26 - loss: 0.13 - ETA: 3:41:11 - loss: 0.13 - ETA: 3:40:55 - loss: 0.13 - ETA: 3:40:40 - loss: 0.13 - ETA: 3:40:25 - loss: 0.13 - ETA: 3:40:10 - loss: 0.13 - ETA: 3:39:56 - loss: 0.13 - ETA: 3:39:48 - loss: 0.13 - ETA: 3:39:37 - loss: 0.13 - ETA: 3:39:24 - loss: 0.13 - ETA: 3:39:08 - loss: 0.13 - ETA: 3:38:56 - loss: 0.13 - ETA: 3:38:42 - loss: 0.13 - ETA: 3:38:29 - loss: 0.13 - ETA: 3:38:19 - loss: 0.13 - ETA: 3:38:06 - loss: 0.13 - ETA: 3:37:54 - loss: 0.13 - ETA: 3:37:40 - loss: 0.13 - ETA: 3:37:25 - loss: 0.13 - ETA: 3:37:12 - loss: 0.13 - ETA: 3:36:58 - loss: 0.13 - ETA: 3:36:44 - loss: 0.13 - ETA: 3:36:31 - loss: 0.13 - ETA: 3:36:16 - loss: 0.13 - ETA: 3:36:04 - loss: 0.13 - ETA: 3:35:50 - loss: 0.13 - ETA: 3:35:36 - loss: 0.13 - ETA: 3:35:25 - loss: 0.13 - ETA: 3:35:16 - loss: 0.13 - ETA: 3:35:03 - loss: 0.13 - ETA: 3:34:50 - loss: 0.13 - ETA: 3:34:35 - loss: 0.13 - ETA: 3:34:21 - loss: 0.13 - ETA: 3:34:07 - loss: 0.13 - ETA: 3:33:54 - loss: 0.13 - ETA: 3:33:39 - loss: 0.13 - ETA: 3:33:25 - loss: 0.13 - ETA: 3:33:11 - loss: 0.13 - ETA: 3:32:56 - loss: 0.13 - ETA: 3:32:41 - loss: 0.13 - ETA: 3:32:28 - loss: 0.13 - ETA: 3:32:14 - loss: 0.13 - ETA: 3:32:01 - loss: 0.13 - ETA: 3:31:48 - loss: 0.13 - ETA: 3:31:35 - loss: 0.13 - ETA: 3:31:22 - loss: 0.13 - ETA: 3:31:10 - loss: 0.13 - ETA: 3:30:58 - loss: 0.13 - ETA: 3:30:44 - loss: 0.13 - ETA: 3:30:30 - loss: 0.13 - ETA: 3:30:15 - loss: 0.13 - ETA: 3:30:01 - loss: 0.13 - ETA: 3:29:47 - loss: 0.13 - ETA: 3:29:33 - loss: 0.13 - ETA: 3:29:20 - loss: 0.13 - ETA: 3:29:05 - loss: 0.13 - ETA: 3:28:51 - loss: 0.13 - ETA: 3:28:37 - loss: 0.13 - ETA: 3:28:23 - loss: 0.13 - ETA: 3:28:09 - loss: 0.13 - ETA: 3:27:55 - loss: 0.13 - ETA: 3:27:41 - loss: 0.13 - ETA: 3:27:27 - loss: 0.13 - ETA: 3:27:13 - loss: 0.13 - ETA: 3:26:59 - loss: 0.13 - ETA: 3:26:46 - loss: 0.13 - ETA: 3:26:32 - loss: 0.13 - ETA: 3:26:18 - loss: 0.13 - ETA: 3:26:04 - loss: 0.13 - ETA: 3:25:51 - loss: 0.13 - ETA: 3:25:37 - loss: 0.13 - ETA: 3:25:23 - loss: 0.13 - ETA: 3:25:10 - loss: 0.13 - ETA: 3:24:57 - loss: 0.13 - ETA: 3:24:43 - loss: 0.13 - ETA: 3:24:30 - loss: 0.13 - ETA: 3:24:18 - loss: 0.13 - ETA: 3:24:05 - loss: 0.12 - ETA: 3:23:52 - loss: 0.12 - ETA: 3:23:39 - loss: 0.12 - ETA: 3:23:27 - loss: 0.12 - ETA: 3:23:13 - loss: 0.12 - ETA: 3:23:01 - loss: 0.12 - ETA: 3:22:51 - loss: 0.12 - ETA: 3:22:39 - loss: 0.12 - ETA: 3:22:29 - loss: 0.12 - ETA: 3:22:24 - loss: 0.12 - ETA: 3:22:14 - loss: 0.12 - ETA: 3:22:03 - loss: 0.12 - ETA: 3:21:51 - loss: 0.12 - ETA: 3:21:38 - loss: 0.12 - ETA: 3:21:26 - loss: 0.12 - ETA: 3:21:14 - loss: 0.12 - ETA: 3:21:01 - loss: 0.12 - ETA: 3:20:50 - loss: 0.12 - ETA: 3:20:37 - loss: 0.12 - ETA: 3:20:24 - loss: 0.12 - ETA: 3:20:16 - loss: 0.12 - ETA: 3:20:04 - loss: 0.12 - ETA: 3:19:51 - loss: 0.12 - ETA: 3:19:39 - loss: 0.12 - ETA: 3:19:26 - loss: 0.12 - ETA: 3:19:14 - loss: 0.12 - ETA: 3:19:01 - loss: 0.12 - ETA: 3:18:48 - loss: 0.12 - ETA: 3:18:34 - loss: 0.12 - ETA: 3:18:21 - loss: 0.12 - ETA: 3:18:07 - loss: 0.12 - ETA: 3:17:54 - loss: 0.12 - ETA: 3:17:43 - loss: 0.12 - ETA: 3:17:31 - loss: 0.12 - ETA: 3:17:18 - loss: 0.12 - ETA: 3:17:05 - loss: 0.12 - ETA: 3:16:53 - loss: 0.12 - ETA: 3:16:40 - loss: 0.12 - ETA: 3:16:27 - loss: 0.12 - ETA: 3:16:17 - loss: 0.12 - ETA: 3:16:07 - loss: 0.12 - ETA: 3:15:57 - loss: 0.12 - ETA: 3:15:44 - loss: 0.12 - ETA: 3:15:31 - loss: 0.12 - ETA: 3:15:17 - loss: 0.12 - ETA: 3:15:03 - loss: 0.12 - ETA: 3:14:53 - loss: 0.12 - ETA: 3:14:43 - loss: 0.12 - ETA: 3:14:34 - loss: 0.12 - ETA: 3:14:27 - loss: 0.12 - ETA: 3:14:20 - loss: 0.12 - ETA: 3:14:15 - loss: 0.12 - ETA: 3:14:05 - loss: 0.12 - ETA: 3:13:57 - loss: 0.12 - ETA: 3:13:50 - loss: 0.12 - ETA: 3:13:41 - loss: 0.12 - ETA: 3:13:32 - loss: 0.12 - ETA: 3:13:22 - loss: 0.12 - ETA: 3:13:13 - loss: 0.12 - ETA: 3:13:03 - loss: 0.12 - ETA: 3:12:51 - loss: 0.12 - ETA: 3:12:40 - loss: 0.12 - ETA: 3:12:32 - loss: 0.12 - ETA: 3:12:21 - loss: 0.12 - ETA: 3:12:12 - loss: 0.12 - ETA: 3:12:00 - loss: 0.12 - ETA: 3:11:49 - loss: 0.12 - ETA: 3:11:37 - loss: 0.12 - ETA: 3:11:28 - loss: 0.12 - ETA: 3:11:19 - loss: 0.12 - ETA: 3:11:10 - loss: 0.12 - ETA: 3:10:58 - loss: 0.12 - ETA: 3:10:45 - loss: 0.12 - ETA: 3:10:32 - loss: 0.12 - ETA: 3:10:19 - loss: 0.12 - ETA: 3:10:05 - loss: 0.12 - ETA: 3:10:06 - loss: 0.12 - ETA: 3:09:59 - loss: 0.12 - ETA: 3:09:56 - loss: 0.12 - ETA: 3:09:49 - loss: 0.12 - ETA: 3:09:42 - loss: 0.12 - ETA: 3:09:35 - loss: 0.12 - ETA: 3:09:29 - loss: 0.12 - ETA: 3:09:23 - loss: 0.12 - ETA: 3:09:12 - loss: 0.12 - ETA: 3:09:00 - loss: 0.12 - ETA: 3:08:48 - loss: 0.12 - ETA: 3:08:35 - loss: 0.12 - ETA: 3:08:23 - loss: 0.12 - ETA: 3:08:10 - loss: 0.12 - ETA: 3:07:57 - loss: 0.12 - ETA: 3:07:44 - loss: 0.12 - ETA: 3:07:34 - loss: 0.12 - ETA: 3:07:29 - loss: 0.12 - ETA: 3:07:24 - loss: 0.12 - ETA: 3:07:21 - loss: 0.12 - ETA: 3:07:14 - loss: 0.12 - ETA: 3:07:04 - loss: 0.12 - ETA: 3:06:52 - loss: 0.12 - ETA: 3:06:41 - loss: 0.12 - ETA: 3:06:32 - loss: 0.12 - ETA: 3:06:21 - loss: 0.12 - ETA: 3:06:11 - loss: 0.12 - ETA: 3:06:00 - loss: 0.12 - ETA: 3:05:48 - loss: 0.12 - ETA: 3:05:38 - loss: 0.12 - ETA: 3:05:25 - loss: 0.1233 74368/154783 [=============>................] - ETA: 3:05:13 - loss: 0.12 - ETA: 3:05:00 - loss: 0.12 - ETA: 3:04:48 - loss: 0.12 - ETA: 3:04:36 - loss: 0.12 - ETA: 3:04:24 - loss: 0.12 - ETA: 3:04:11 - loss: 0.12 - ETA: 3:03:58 - loss: 0.12 - ETA: 3:03:45 - loss: 0.12 - ETA: 3:03:32 - loss: 0.12 - ETA: 3:03:19 - loss: 0.12 - ETA: 3:03:05 - loss: 0.12 - ETA: 3:02:52 - loss: 0.12 - ETA: 3:02:39 - loss: 0.12 - ETA: 3:02:26 - loss: 0.12 - ETA: 3:02:13 - loss: 0.12 - ETA: 3:02:00 - loss: 0.12 - ETA: 3:01:47 - loss: 0.12 - ETA: 3:01:35 - loss: 0.12 - ETA: 3:01:23 - loss: 0.12 - ETA: 3:01:11 - loss: 0.12 - ETA: 3:00:58 - loss: 0.12 - ETA: 3:00:45 - loss: 0.12 - ETA: 3:00:33 - loss: 0.12 - ETA: 3:00:21 - loss: 0.12 - ETA: 3:00:09 - loss: 0.12 - ETA: 2:59:56 - loss: 0.12 - ETA: 2:59:43 - loss: 0.12 - ETA: 2:59:31 - loss: 0.12 - ETA: 2:59:19 - loss: 0.12 - ETA: 2:59:06 - loss: 0.12 - ETA: 2:58:54 - loss: 0.12 - ETA: 2:58:42 - loss: 0.12 - ETA: 2:58:32 - loss: 0.12 - ETA: 2:58:22 - loss: 0.12 - ETA: 2:58:11 - loss: 0.12 - ETA: 2:57:59 - loss: 0.12 - ETA: 2:57:47 - loss: 0.12 - ETA: 2:57:35 - loss: 0.12 - ETA: 2:57:22 - loss: 0.12 - ETA: 2:57:10 - loss: 0.12 - ETA: 2:56:58 - loss: 0.12 - ETA: 2:56:46 - loss: 0.12 - ETA: 2:56:34 - loss: 0.12 - ETA: 2:56:23 - loss: 0.12 - ETA: 2:56:11 - loss: 0.12 - ETA: 2:55:58 - loss: 0.12 - ETA: 2:55:47 - loss: 0.12 - ETA: 2:55:36 - loss: 0.12 - ETA: 2:55:25 - loss: 0.12 - ETA: 2:55:14 - loss: 0.12 - ETA: 2:55:02 - loss: 0.12 - ETA: 2:54:52 - loss: 0.12 - ETA: 2:54:40 - loss: 0.12 - ETA: 2:54:28 - loss: 0.12 - ETA: 2:54:17 - loss: 0.12 - ETA: 2:54:05 - loss: 0.12 - ETA: 2:53:54 - loss: 0.12 - ETA: 2:53:42 - loss: 0.12 - ETA: 2:53:31 - loss: 0.12 - ETA: 2:53:21 - loss: 0.12 - ETA: 2:53:09 - loss: 0.12 - ETA: 2:53:01 - loss: 0.12 - ETA: 2:52:50 - loss: 0.12 - ETA: 2:52:40 - loss: 0.12 - ETA: 2:52:30 - loss: 0.12 - ETA: 2:52:21 - loss: 0.12 - ETA: 2:52:09 - loss: 0.12 - ETA: 2:51:58 - loss: 0.12 - ETA: 2:51:47 - loss: 0.12 - ETA: 2:51:36 - loss: 0.11 - ETA: 2:51:25 - loss: 0.11 - ETA: 2:51:15 - loss: 0.11 - ETA: 2:51:04 - loss: 0.11 - ETA: 2:50:53 - loss: 0.11 - ETA: 2:50:42 - loss: 0.11 - ETA: 2:50:30 - loss: 0.11 - ETA: 2:50:19 - loss: 0.11 - ETA: 2:50:08 - loss: 0.11 - ETA: 2:49:57 - loss: 0.11 - ETA: 2:49:46 - loss: 0.11 - ETA: 2:49:34 - loss: 0.11 - ETA: 2:49:23 - loss: 0.11 - ETA: 2:49:13 - loss: 0.11 - ETA: 2:49:02 - loss: 0.11 - ETA: 2:48:51 - loss: 0.11 - ETA: 2:48:40 - loss: 0.11 - ETA: 2:48:32 - loss: 0.11 - ETA: 2:48:22 - loss: 0.11 - ETA: 2:48:12 - loss: 0.11 - ETA: 2:48:01 - loss: 0.11 - ETA: 2:47:51 - loss: 0.11 - ETA: 2:47:41 - loss: 0.11 - ETA: 2:47:30 - loss: 0.11 - ETA: 2:47:19 - loss: 0.11 - ETA: 2:47:09 - loss: 0.11 - ETA: 2:47:00 - loss: 0.11 - ETA: 2:46:52 - loss: 0.11 - ETA: 2:46:42 - loss: 0.11 - ETA: 2:46:33 - loss: 0.11 - ETA: 2:46:24 - loss: 0.11 - ETA: 2:46:14 - loss: 0.11 - ETA: 2:46:04 - loss: 0.11 - ETA: 2:45:55 - loss: 0.11 - ETA: 2:45:46 - loss: 0.11 - ETA: 2:45:35 - loss: 0.11 - ETA: 2:45:26 - loss: 0.11 - ETA: 2:45:16 - loss: 0.11 - ETA: 2:45:08 - loss: 0.11 - ETA: 2:44:59 - loss: 0.11 - ETA: 2:44:48 - loss: 0.11 - ETA: 2:44:37 - loss: 0.11 - ETA: 2:44:28 - loss: 0.11 - ETA: 2:44:18 - loss: 0.11 - ETA: 2:44:08 - loss: 0.11 - ETA: 2:43:58 - loss: 0.11 - ETA: 2:43:46 - loss: 0.11 - ETA: 2:43:35 - loss: 0.11 - ETA: 2:43:24 - loss: 0.11 - ETA: 2:43:15 - loss: 0.11 - ETA: 2:43:05 - loss: 0.11 - ETA: 2:42:55 - loss: 0.11 - ETA: 2:42:43 - loss: 0.11 - ETA: 2:42:32 - loss: 0.11 - ETA: 2:42:22 - loss: 0.11 - ETA: 2:42:11 - loss: 0.11 - ETA: 2:42:00 - loss: 0.11 - ETA: 2:41:50 - loss: 0.11 - ETA: 2:41:40 - loss: 0.11 - ETA: 2:41:30 - loss: 0.11 - ETA: 2:41:20 - loss: 0.11 - ETA: 2:41:11 - loss: 0.11 - ETA: 2:41:01 - loss: 0.11 - ETA: 2:40:50 - loss: 0.11 - ETA: 2:40:39 - loss: 0.11 - ETA: 2:40:29 - loss: 0.11 - ETA: 2:40:20 - loss: 0.11 - ETA: 2:40:09 - loss: 0.11 - ETA: 2:39:58 - loss: 0.11 - ETA: 2:39:48 - loss: 0.11 - ETA: 2:39:37 - loss: 0.11 - ETA: 2:39:26 - loss: 0.11 - ETA: 2:39:15 - loss: 0.11 - ETA: 2:39:05 - loss: 0.11 - ETA: 2:38:54 - loss: 0.11 - ETA: 2:38:43 - loss: 0.11 - ETA: 2:38:32 - loss: 0.11 - ETA: 2:38:21 - loss: 0.11 - ETA: 2:38:11 - loss: 0.11 - ETA: 2:38:00 - loss: 0.11 - ETA: 2:37:49 - loss: 0.11 - ETA: 2:37:38 - loss: 0.11 - ETA: 2:37:27 - loss: 0.11 - ETA: 2:37:16 - loss: 0.11 - ETA: 2:37:05 - loss: 0.11 - ETA: 2:36:54 - loss: 0.11 - ETA: 2:36:44 - loss: 0.11 - ETA: 2:36:35 - loss: 0.11 - ETA: 2:36:25 - loss: 0.11 - ETA: 2:36:16 - loss: 0.11 - ETA: 2:36:07 - loss: 0.11 - ETA: 2:35:58 - loss: 0.11 - ETA: 2:35:49 - loss: 0.11 - ETA: 2:35:40 - loss: 0.11 - ETA: 2:35:29 - loss: 0.11 - ETA: 2:35:18 - loss: 0.11 - ETA: 2:35:07 - loss: 0.11 - ETA: 2:34:57 - loss: 0.11 - ETA: 2:34:46 - loss: 0.11 - ETA: 2:34:35 - loss: 0.11 - ETA: 2:34:24 - loss: 0.11 - ETA: 2:34:14 - loss: 0.11 - ETA: 2:34:03 - loss: 0.11 - ETA: 2:33:52 - loss: 0.11 - ETA: 2:33:41 - loss: 0.11 - ETA: 2:33:31 - loss: 0.11 - ETA: 2:33:20 - loss: 0.11 - ETA: 2:33:10 - loss: 0.11 - ETA: 2:33:01 - loss: 0.11 - ETA: 2:32:54 - loss: 0.11 - ETA: 2:32:44 - loss: 0.11 - ETA: 2:32:33 - loss: 0.11 - ETA: 2:32:23 - loss: 0.11 - ETA: 2:32:13 - loss: 0.11 - ETA: 2:32:04 - loss: 0.11 - ETA: 2:31:54 - loss: 0.11 - ETA: 2:31:44 - loss: 0.11 - ETA: 2:31:34 - loss: 0.11 - ETA: 2:31:25 - loss: 0.11 - ETA: 2:31:15 - loss: 0.11 - ETA: 2:31:04 - loss: 0.11 - ETA: 2:30:55 - loss: 0.11 - ETA: 2:30:46 - loss: 0.11 - ETA: 2:30:36 - loss: 0.11 - ETA: 2:30:26 - loss: 0.11 - ETA: 2:30:15 - loss: 0.11 - ETA: 2:30:06 - loss: 0.11 - ETA: 2:29:57 - loss: 0.11 - ETA: 2:29:49 - loss: 0.11 - ETA: 2:29:41 - loss: 0.11 - ETA: 2:29:34 - loss: 0.11 - ETA: 2:29:24 - loss: 0.11 - ETA: 2:29:16 - loss: 0.11 - ETA: 2:29:06 - loss: 0.11 - ETA: 2:28:57 - loss: 0.11 - ETA: 2:28:48 - loss: 0.11 - ETA: 2:28:39 - loss: 0.11 - ETA: 2:28:30 - loss: 0.11 - ETA: 2:28:22 - loss: 0.11 - ETA: 2:28:13 - loss: 0.11 - ETA: 2:28:03 - loss: 0.11 - ETA: 2:27:54 - loss: 0.11 - ETA: 2:27:44 - loss: 0.11 - ETA: 2:27:34 - loss: 0.11 - ETA: 2:27:23 - loss: 0.11 - ETA: 2:27:14 - loss: 0.11 - ETA: 2:27:05 - loss: 0.11 - ETA: 2:26:57 - loss: 0.11 - ETA: 2:26:50 - loss: 0.11 - ETA: 2:26:43 - loss: 0.11 - ETA: 2:26:34 - loss: 0.11 - ETA: 2:26:26 - loss: 0.11 - ETA: 2:26:18 - loss: 0.11 - ETA: 2:26:09 - loss: 0.11 - ETA: 2:26:01 - loss: 0.11 - ETA: 2:25:54 - loss: 0.11 - ETA: 2:25:48 - loss: 0.11 - ETA: 2:25:41 - loss: 0.11 - ETA: 2:25:32 - loss: 0.11 - ETA: 2:25:23 - loss: 0.11 - ETA: 2:25:13 - loss: 0.11 - ETA: 2:25:03 - loss: 0.11 - ETA: 2:24:54 - loss: 0.11 - ETA: 2:24:44 - loss: 0.11 - ETA: 2:24:35 - loss: 0.11 - ETA: 2:24:25 - loss: 0.11 - ETA: 2:24:15 - loss: 0.11 - ETA: 2:24:06 - loss: 0.11 - ETA: 2:23:57 - loss: 0.11 - ETA: 2:23:47 - loss: 0.11 - ETA: 2:23:38 - loss: 0.11 - ETA: 2:23:28 - loss: 0.11 - ETA: 2:23:18 - loss: 0.11 - ETA: 2:23:08 - loss: 0.11 - ETA: 2:22:58 - loss: 0.11 - ETA: 2:22:49 - loss: 0.11 - ETA: 2:22:39 - loss: 0.11 - ETA: 2:22:29 - loss: 0.11 - ETA: 2:22:19 - loss: 0.11 - ETA: 2:22:10 - loss: 0.11 - ETA: 2:22:00 - loss: 0.11 - ETA: 2:21:51 - loss: 0.11 - ETA: 2:21:42 - loss: 0.11 - ETA: 2:21:32 - loss: 0.11 - ETA: 2:21:23 - loss: 0.11 - ETA: 2:21:13 - loss: 0.11 - ETA: 2:21:03 - loss: 0.11 - ETA: 2:20:54 - loss: 0.11 - ETA: 2:20:44 - loss: 0.11 - ETA: 2:20:35 - loss: 0.11 - ETA: 2:20:25 - loss: 0.11 - ETA: 2:20:16 - loss: 0.11 - ETA: 2:20:06 - loss: 0.11 - ETA: 2:19:57 - loss: 0.11 - ETA: 2:19:48 - loss: 0.11 - ETA: 2:19:39 - loss: 0.11 - ETA: 2:19:29 - loss: 0.11 - ETA: 2:19:20 - loss: 0.11 - ETA: 2:19:11 - loss: 0.11 - ETA: 2:19:02 - loss: 0.11 - ETA: 2:18:52 - loss: 0.11 - ETA: 2:18:43 - loss: 0.11 - ETA: 2:18:34 - loss: 0.11 - ETA: 2:18:24 - loss: 0.11 - ETA: 2:18:15 - loss: 0.11 - ETA: 2:18:05 - loss: 0.11 - ETA: 2:17:56 - loss: 0.11 - ETA: 2:17:46 - loss: 0.11 - ETA: 2:17:37 - loss: 0.11 - ETA: 2:17:28 - loss: 0.11 - ETA: 2:17:19 - loss: 0.11 - ETA: 2:17:10 - loss: 0.11 - ETA: 2:17:00 - loss: 0.11 - ETA: 2:16:51 - loss: 0.11 - ETA: 2:16:42 - loss: 0.11 - ETA: 2:16:32 - loss: 0.11 - ETA: 2:16:23 - loss: 0.11 - ETA: 2:16:14 - loss: 0.11 - ETA: 2:16:05 - loss: 0.11 - ETA: 2:15:56 - loss: 0.11 - ETA: 2:15:47 - loss: 0.11 - ETA: 2:15:38 - loss: 0.1108 92992/154783 [=================>............] - ETA: 2:15:29 - loss: 0.11 - ETA: 2:15:20 - loss: 0.11 - ETA: 2:15:12 - loss: 0.11 - ETA: 2:15:03 - loss: 0.11 - ETA: 2:14:54 - loss: 0.11 - ETA: 2:14:45 - loss: 0.11 - ETA: 2:14:37 - loss: 0.11 - ETA: 2:14:28 - loss: 0.11 - ETA: 2:14:19 - loss: 0.11 - ETA: 2:14:10 - loss: 0.11 - ETA: 2:14:01 - loss: 0.11 - ETA: 2:13:52 - loss: 0.11 - ETA: 2:13:43 - loss: 0.11 - ETA: 2:13:34 - loss: 0.11 - ETA: 2:13:25 - loss: 0.11 - ETA: 2:13:16 - loss: 0.11 - ETA: 2:13:07 - loss: 0.11 - ETA: 2:12:58 - loss: 0.11 - ETA: 2:12:49 - loss: 0.11 - ETA: 2:12:40 - loss: 0.11 - ETA: 2:12:31 - loss: 0.11 - ETA: 2:12:22 - loss: 0.11 - ETA: 2:12:12 - loss: 0.11 - ETA: 2:12:03 - loss: 0.11 - ETA: 2:11:54 - loss: 0.10 - ETA: 2:11:45 - loss: 0.10 - ETA: 2:11:36 - loss: 0.10 - ETA: 2:11:27 - loss: 0.10 - ETA: 2:11:18 - loss: 0.10 - ETA: 2:11:09 - loss: 0.10 - ETA: 2:11:00 - loss: 0.10 - ETA: 2:10:51 - loss: 0.10 - ETA: 2:10:42 - loss: 0.10 - ETA: 2:10:33 - loss: 0.10 - ETA: 2:10:24 - loss: 0.10 - ETA: 2:10:16 - loss: 0.10 - ETA: 2:10:07 - loss: 0.10 - ETA: 2:09:58 - loss: 0.10 - ETA: 2:09:50 - loss: 0.10 - ETA: 2:09:43 - loss: 0.10 - ETA: 2:09:35 - loss: 0.10 - ETA: 2:09:26 - loss: 0.10 - ETA: 2:09:17 - loss: 0.10 - ETA: 2:09:08 - loss: 0.10 - ETA: 2:09:00 - loss: 0.10 - ETA: 2:08:51 - loss: 0.10 - ETA: 2:08:43 - loss: 0.10 - ETA: 2:08:35 - loss: 0.10 - ETA: 2:08:27 - loss: 0.10 - ETA: 2:08:18 - loss: 0.10 - ETA: 2:08:09 - loss: 0.10 - ETA: 2:08:01 - loss: 0.10 - ETA: 2:07:52 - loss: 0.10 - ETA: 2:07:44 - loss: 0.10 - ETA: 2:07:36 - loss: 0.10 - ETA: 2:07:27 - loss: 0.10 - ETA: 2:07:19 - loss: 0.10 - ETA: 2:07:11 - loss: 0.10 - ETA: 2:07:02 - loss: 0.10 - ETA: 2:06:55 - loss: 0.10 - ETA: 2:06:47 - loss: 0.10 - ETA: 2:06:38 - loss: 0.10 - ETA: 2:06:30 - loss: 0.10 - ETA: 2:06:22 - loss: 0.10 - ETA: 2:06:13 - loss: 0.10 - ETA: 2:06:05 - loss: 0.10 - ETA: 2:05:56 - loss: 0.10 - ETA: 2:05:48 - loss: 0.10 - ETA: 2:05:39 - loss: 0.10 - ETA: 2:05:30 - loss: 0.10 - ETA: 2:05:21 - loss: 0.10 - ETA: 2:05:13 - loss: 0.10 - ETA: 2:05:04 - loss: 0.10 - ETA: 2:04:55 - loss: 0.10 - ETA: 2:04:47 - loss: 0.10 - ETA: 2:04:39 - loss: 0.10 - ETA: 2:04:30 - loss: 0.10 - ETA: 2:04:22 - loss: 0.10 - ETA: 2:04:13 - loss: 0.10 - ETA: 2:04:04 - loss: 0.10 - ETA: 2:03:56 - loss: 0.10 - ETA: 2:03:47 - loss: 0.10 - ETA: 2:03:38 - loss: 0.10 - ETA: 2:03:30 - loss: 0.10 - ETA: 2:03:21 - loss: 0.10 - ETA: 2:03:12 - loss: 0.10 - ETA: 2:03:03 - loss: 0.10 - ETA: 2:02:55 - loss: 0.10 - ETA: 2:02:47 - loss: 0.10 - ETA: 2:02:38 - loss: 0.10 - ETA: 2:02:30 - loss: 0.10 - ETA: 2:02:22 - loss: 0.10 - ETA: 2:02:13 - loss: 0.10 - ETA: 2:02:04 - loss: 0.10 - ETA: 2:01:55 - loss: 0.10 - ETA: 2:01:48 - loss: 0.10 - ETA: 2:01:40 - loss: 0.10 - ETA: 2:01:32 - loss: 0.10 - ETA: 2:01:24 - loss: 0.10 - ETA: 2:01:16 - loss: 0.10 - ETA: 2:01:08 - loss: 0.10 - ETA: 2:01:00 - loss: 0.10 - ETA: 2:00:52 - loss: 0.10 - ETA: 2:00:43 - loss: 0.10 - ETA: 2:00:35 - loss: 0.10 - ETA: 2:00:27 - loss: 0.10 - ETA: 2:00:20 - loss: 0.10 - ETA: 2:00:12 - loss: 0.10 - ETA: 2:00:03 - loss: 0.10 - ETA: 1:59:55 - loss: 0.10 - ETA: 1:59:47 - loss: 0.10 - ETA: 1:59:39 - loss: 0.10 - ETA: 1:59:31 - loss: 0.10 - ETA: 1:59:23 - loss: 0.10 - ETA: 1:59:15 - loss: 0.10 - ETA: 1:59:06 - loss: 0.10 - ETA: 1:58:58 - loss: 0.10 - ETA: 1:58:50 - loss: 0.10 - ETA: 1:58:42 - loss: 0.10 - ETA: 1:58:33 - loss: 0.10 - ETA: 1:58:25 - loss: 0.10 - ETA: 1:58:17 - loss: 0.10 - ETA: 1:58:09 - loss: 0.10 - ETA: 1:58:00 - loss: 0.10 - ETA: 1:57:52 - loss: 0.10 - ETA: 1:57:45 - loss: 0.10 - ETA: 1:57:37 - loss: 0.10 - ETA: 1:57:29 - loss: 0.10 - ETA: 1:57:21 - loss: 0.10 - ETA: 1:57:13 - loss: 0.10 - ETA: 1:57:04 - loss: 0.10 - ETA: 1:56:56 - loss: 0.10 - ETA: 1:56:48 - loss: 0.10 - ETA: 1:56:39 - loss: 0.10 - ETA: 1:56:31 - loss: 0.10 - ETA: 1:56:23 - loss: 0.10 - ETA: 1:56:15 - loss: 0.10 - ETA: 1:56:07 - loss: 0.10 - ETA: 1:55:59 - loss: 0.10 - ETA: 1:55:51 - loss: 0.10 - ETA: 1:55:43 - loss: 0.10 - ETA: 1:55:35 - loss: 0.10 - ETA: 1:55:26 - loss: 0.10 - ETA: 1:55:18 - loss: 0.10 - ETA: 1:55:10 - loss: 0.10 - ETA: 1:55:02 - loss: 0.10 - ETA: 1:54:54 - loss: 0.10 - ETA: 1:54:46 - loss: 0.10 - ETA: 1:54:38 - loss: 0.10 - ETA: 1:54:30 - loss: 0.10 - ETA: 1:54:22 - loss: 0.10 - ETA: 1:54:16 - loss: 0.10 - ETA: 1:54:10 - loss: 0.10 - ETA: 1:54:02 - loss: 0.10 - ETA: 1:53:55 - loss: 0.10 - ETA: 1:53:47 - loss: 0.10 - ETA: 1:53:39 - loss: 0.10 - ETA: 1:53:32 - loss: 0.10 - ETA: 1:53:24 - loss: 0.10 - ETA: 1:53:17 - loss: 0.10 - ETA: 1:53:09 - loss: 0.10 - ETA: 1:53:01 - loss: 0.10 - ETA: 1:52:53 - loss: 0.10 - ETA: 1:52:45 - loss: 0.10 - ETA: 1:52:38 - loss: 0.10 - ETA: 1:52:30 - loss: 0.10 - ETA: 1:52:22 - loss: 0.10 - ETA: 1:52:14 - loss: 0.10 - ETA: 1:52:06 - loss: 0.10 - ETA: 1:51:58 - loss: 0.10 - ETA: 1:51:50 - loss: 0.10 - ETA: 1:51:42 - loss: 0.10 - ETA: 1:51:34 - loss: 0.10 - ETA: 1:51:26 - loss: 0.10 - ETA: 1:51:18 - loss: 0.10 - ETA: 1:51:09 - loss: 0.10 - ETA: 1:51:02 - loss: 0.10 - ETA: 1:50:54 - loss: 0.10 - ETA: 1:50:46 - loss: 0.10 - ETA: 1:50:38 - loss: 0.10 - ETA: 1:50:31 - loss: 0.10 - ETA: 1:50:24 - loss: 0.10 - ETA: 1:50:16 - loss: 0.10 - ETA: 1:50:08 - loss: 0.10 - ETA: 1:50:00 - loss: 0.10 - ETA: 1:49:53 - loss: 0.10 - ETA: 1:49:46 - loss: 0.10 - ETA: 1:49:38 - loss: 0.10 - ETA: 1:49:30 - loss: 0.10 - ETA: 1:49:22 - loss: 0.10 - ETA: 1:49:15 - loss: 0.10 - ETA: 1:49:08 - loss: 0.10 - ETA: 1:49:00 - loss: 0.10 - ETA: 1:48:53 - loss: 0.10 - ETA: 1:48:45 - loss: 0.10 - ETA: 1:48:38 - loss: 0.10 - ETA: 1:48:30 - loss: 0.10 - ETA: 1:48:22 - loss: 0.10 - ETA: 1:48:14 - loss: 0.10 - ETA: 1:48:06 - loss: 0.10 - ETA: 1:47:58 - loss: 0.10 - ETA: 1:47:50 - loss: 0.10 - ETA: 1:47:42 - loss: 0.10 - ETA: 1:47:35 - loss: 0.10 - ETA: 1:47:27 - loss: 0.10 - ETA: 1:47:20 - loss: 0.10 - ETA: 1:47:12 - loss: 0.10 - ETA: 1:47:04 - loss: 0.10 - ETA: 1:46:56 - loss: 0.10 - ETA: 1:46:48 - loss: 0.10 - ETA: 1:46:40 - loss: 0.10 - ETA: 1:46:32 - loss: 0.10 - ETA: 1:46:24 - loss: 0.10 - ETA: 1:46:16 - loss: 0.10 - ETA: 1:46:09 - loss: 0.10 - ETA: 1:46:01 - loss: 0.10 - ETA: 1:45:53 - loss: 0.10 - ETA: 1:45:45 - loss: 0.10 - ETA: 1:45:37 - loss: 0.10 - ETA: 1:45:29 - loss: 0.10 - ETA: 1:45:22 - loss: 0.10 - ETA: 1:45:14 - loss: 0.10 - ETA: 1:45:07 - loss: 0.10 - ETA: 1:44:59 - loss: 0.10 - ETA: 1:44:52 - loss: 0.10 - ETA: 1:44:45 - loss: 0.10 - ETA: 1:44:37 - loss: 0.10 - ETA: 1:44:31 - loss: 0.10 - ETA: 1:44:23 - loss: 0.10 - ETA: 1:44:15 - loss: 0.10 - ETA: 1:44:08 - loss: 0.10 - ETA: 1:44:00 - loss: 0.10 - ETA: 1:43:52 - loss: 0.10 - ETA: 1:43:45 - loss: 0.10 - ETA: 1:43:37 - loss: 0.10 - ETA: 1:43:30 - loss: 0.10 - ETA: 1:43:23 - loss: 0.10 - ETA: 1:43:16 - loss: 0.10 - ETA: 1:43:08 - loss: 0.10 - ETA: 1:43:00 - loss: 0.10 - ETA: 1:42:53 - loss: 0.10 - ETA: 1:42:45 - loss: 0.10 - ETA: 1:42:37 - loss: 0.10 - ETA: 1:42:30 - loss: 0.10 - ETA: 1:42:22 - loss: 0.10 - ETA: 1:42:14 - loss: 0.10 - ETA: 1:42:06 - loss: 0.10 - ETA: 1:41:59 - loss: 0.10 - ETA: 1:41:51 - loss: 0.10 - ETA: 1:41:43 - loss: 0.10 - ETA: 1:41:36 - loss: 0.10 - ETA: 1:41:28 - loss: 0.10 - ETA: 1:41:20 - loss: 0.10 - ETA: 1:41:13 - loss: 0.10 - ETA: 1:41:05 - loss: 0.10 - ETA: 1:40:57 - loss: 0.10 - ETA: 1:40:50 - loss: 0.10 - ETA: 1:40:42 - loss: 0.10 - ETA: 1:40:35 - loss: 0.10 - ETA: 1:40:27 - loss: 0.10 - ETA: 1:40:19 - loss: 0.10 - ETA: 1:40:12 - loss: 0.10 - ETA: 1:40:04 - loss: 0.10 - ETA: 1:39:56 - loss: 0.10 - ETA: 1:39:49 - loss: 0.10 - ETA: 1:39:41 - loss: 0.10 - ETA: 1:39:34 - loss: 0.10 - ETA: 1:39:26 - loss: 0.10 - ETA: 1:39:19 - loss: 0.10 - ETA: 1:39:11 - loss: 0.10 - ETA: 1:39:03 - loss: 0.10 - ETA: 1:38:56 - loss: 0.10 - ETA: 1:38:48 - loss: 0.10 - ETA: 1:38:41 - loss: 0.10 - ETA: 1:38:33 - loss: 0.10 - ETA: 1:38:26 - loss: 0.10 - ETA: 1:38:18 - loss: 0.10 - ETA: 1:38:11 - loss: 0.10 - ETA: 1:38:03 - loss: 0.10 - ETA: 1:37:56 - loss: 0.10 - ETA: 1:37:49 - loss: 0.10 - ETA: 1:37:42 - loss: 0.10 - ETA: 1:37:34 - loss: 0.10 - ETA: 1:37:27 - loss: 0.10 - ETA: 1:37:19 - loss: 0.10 - ETA: 1:37:12 - loss: 0.10 - ETA: 1:37:05 - loss: 0.10 - ETA: 1:36:58 - loss: 0.10 - ETA: 1:36:50 - loss: 0.10 - ETA: 1:36:43 - loss: 0.10 - ETA: 1:36:35 - loss: 0.1025111616/154783 [====================>.........] - ETA: 1:36:28 - loss: 0.10 - ETA: 1:36:20 - loss: 0.10 - ETA: 1:36:13 - loss: 0.10 - ETA: 1:36:06 - loss: 0.10 - ETA: 1:35:58 - loss: 0.10 - ETA: 1:35:51 - loss: 0.10 - ETA: 1:35:44 - loss: 0.10 - ETA: 1:35:37 - loss: 0.10 - ETA: 1:35:30 - loss: 0.10 - ETA: 1:35:22 - loss: 0.10 - ETA: 1:35:15 - loss: 0.10 - ETA: 1:35:08 - loss: 0.10 - ETA: 1:35:01 - loss: 0.10 - ETA: 1:34:53 - loss: 0.10 - ETA: 1:34:46 - loss: 0.10 - ETA: 1:34:39 - loss: 0.10 - ETA: 1:34:31 - loss: 0.10 - ETA: 1:34:24 - loss: 0.10 - ETA: 1:34:17 - loss: 0.10 - ETA: 1:34:09 - loss: 0.10 - ETA: 1:34:02 - loss: 0.10 - ETA: 1:33:55 - loss: 0.10 - ETA: 1:33:47 - loss: 0.10 - ETA: 1:33:40 - loss: 0.10 - ETA: 1:33:33 - loss: 0.10 - ETA: 1:33:26 - loss: 0.10 - ETA: 1:33:18 - loss: 0.10 - ETA: 1:33:11 - loss: 0.10 - ETA: 1:33:04 - loss: 0.10 - ETA: 1:32:57 - loss: 0.10 - ETA: 1:32:50 - loss: 0.10 - ETA: 1:32:43 - loss: 0.10 - ETA: 1:32:35 - loss: 0.10 - ETA: 1:32:28 - loss: 0.10 - ETA: 1:32:21 - loss: 0.10 - ETA: 1:32:14 - loss: 0.10 - ETA: 1:32:06 - loss: 0.10 - ETA: 1:31:59 - loss: 0.10 - ETA: 1:31:52 - loss: 0.10 - ETA: 1:31:45 - loss: 0.10 - ETA: 1:31:38 - loss: 0.10 - ETA: 1:31:30 - loss: 0.10 - ETA: 1:31:23 - loss: 0.10 - ETA: 1:31:16 - loss: 0.10 - ETA: 1:31:09 - loss: 0.10 - ETA: 1:31:02 - loss: 0.10 - ETA: 1:30:55 - loss: 0.10 - ETA: 1:30:47 - loss: 0.10 - ETA: 1:30:40 - loss: 0.10 - ETA: 1:30:33 - loss: 0.10 - ETA: 1:30:26 - loss: 0.10 - ETA: 1:30:19 - loss: 0.10 - ETA: 1:30:11 - loss: 0.10 - ETA: 1:30:04 - loss: 0.10 - ETA: 1:29:57 - loss: 0.10 - ETA: 1:29:50 - loss: 0.10 - ETA: 1:29:43 - loss: 0.10 - ETA: 1:29:36 - loss: 0.10 - ETA: 1:29:29 - loss: 0.10 - ETA: 1:29:22 - loss: 0.10 - ETA: 1:29:15 - loss: 0.10 - ETA: 1:29:08 - loss: 0.10 - ETA: 1:29:01 - loss: 0.10 - ETA: 1:28:54 - loss: 0.10 - ETA: 1:28:46 - loss: 0.10 - ETA: 1:28:39 - loss: 0.10 - ETA: 1:28:32 - loss: 0.10 - ETA: 1:28:25 - loss: 0.10 - ETA: 1:28:18 - loss: 0.10 - ETA: 1:28:11 - loss: 0.10 - ETA: 1:28:04 - loss: 0.10 - ETA: 1:27:57 - loss: 0.10 - ETA: 1:27:50 - loss: 0.10 - ETA: 1:27:43 - loss: 0.10 - ETA: 1:27:36 - loss: 0.10 - ETA: 1:27:29 - loss: 0.10 - ETA: 1:27:22 - loss: 0.10 - ETA: 1:27:15 - loss: 0.10 - ETA: 1:27:08 - loss: 0.10 - ETA: 1:27:01 - loss: 0.10 - ETA: 1:26:54 - loss: 0.10 - ETA: 1:26:47 - loss: 0.10 - ETA: 1:26:40 - loss: 0.10 - ETA: 1:26:33 - loss: 0.10 - ETA: 1:26:26 - loss: 0.10 - ETA: 1:26:19 - loss: 0.10 - ETA: 1:26:12 - loss: 0.10 - ETA: 1:26:05 - loss: 0.10 - ETA: 1:25:58 - loss: 0.10 - ETA: 1:25:51 - loss: 0.10 - ETA: 1:25:44 - loss: 0.10 - ETA: 1:25:37 - loss: 0.10 - ETA: 1:25:31 - loss: 0.10 - ETA: 1:25:24 - loss: 0.10 - ETA: 1:25:17 - loss: 0.10 - ETA: 1:25:11 - loss: 0.10 - ETA: 1:25:04 - loss: 0.10 - ETA: 1:24:58 - loss: 0.10 - ETA: 1:24:51 - loss: 0.10 - ETA: 1:24:44 - loss: 0.10 - ETA: 1:24:38 - loss: 0.10 - ETA: 1:24:31 - loss: 0.10 - ETA: 1:24:24 - loss: 0.10 - ETA: 1:24:17 - loss: 0.10 - ETA: 1:24:11 - loss: 0.10 - ETA: 1:24:04 - loss: 0.10 - ETA: 1:23:57 - loss: 0.10 - ETA: 1:23:50 - loss: 0.10 - ETA: 1:23:43 - loss: 0.10 - ETA: 1:23:36 - loss: 0.10 - ETA: 1:23:29 - loss: 0.10 - ETA: 1:23:22 - loss: 0.10 - ETA: 1:23:16 - loss: 0.10 - ETA: 1:23:09 - loss: 0.10 - ETA: 1:23:02 - loss: 0.10 - ETA: 1:22:55 - loss: 0.09 - ETA: 1:22:48 - loss: 0.09 - ETA: 1:22:41 - loss: 0.09 - ETA: 1:22:34 - loss: 0.09 - ETA: 1:22:27 - loss: 0.09 - ETA: 1:22:20 - loss: 0.09 - ETA: 1:22:13 - loss: 0.09 - ETA: 1:22:07 - loss: 0.09 - ETA: 1:22:00 - loss: 0.09 - ETA: 1:21:53 - loss: 0.09 - ETA: 1:21:46 - loss: 0.09 - ETA: 1:21:39 - loss: 0.09 - ETA: 1:21:32 - loss: 0.09 - ETA: 1:21:25 - loss: 0.09 - ETA: 1:21:18 - loss: 0.09 - ETA: 1:21:11 - loss: 0.09 - ETA: 1:21:05 - loss: 0.09 - ETA: 1:20:58 - loss: 0.09 - ETA: 1:20:51 - loss: 0.09 - ETA: 1:20:44 - loss: 0.09 - ETA: 1:20:37 - loss: 0.09 - ETA: 1:20:31 - loss: 0.09 - ETA: 1:20:24 - loss: 0.09 - ETA: 1:20:17 - loss: 0.09 - ETA: 1:20:10 - loss: 0.09 - ETA: 1:20:03 - loss: 0.09 - ETA: 1:19:56 - loss: 0.09 - ETA: 1:19:49 - loss: 0.09 - ETA: 1:19:43 - loss: 0.09 - ETA: 1:19:36 - loss: 0.09 - ETA: 1:19:29 - loss: 0.09 - ETA: 1:19:22 - loss: 0.09 - ETA: 1:19:15 - loss: 0.09 - ETA: 1:19:09 - loss: 0.09 - ETA: 1:19:02 - loss: 0.09 - ETA: 1:18:55 - loss: 0.09 - ETA: 1:18:48 - loss: 0.09 - ETA: 1:18:41 - loss: 0.09 - ETA: 1:18:35 - loss: 0.09 - ETA: 1:18:28 - loss: 0.09 - ETA: 1:18:21 - loss: 0.09 - ETA: 1:18:14 - loss: 0.09 - ETA: 1:18:08 - loss: 0.09 - ETA: 1:18:01 - loss: 0.09 - ETA: 1:17:54 - loss: 0.09 - ETA: 1:17:48 - loss: 0.09 - ETA: 1:17:41 - loss: 0.09 - ETA: 1:17:34 - loss: 0.09 - ETA: 1:17:27 - loss: 0.09 - ETA: 1:17:21 - loss: 0.09 - ETA: 1:17:14 - loss: 0.09 - ETA: 1:17:07 - loss: 0.09 - ETA: 1:17:01 - loss: 0.09 - ETA: 1:16:54 - loss: 0.09 - ETA: 1:16:48 - loss: 0.09 - ETA: 1:16:42 - loss: 0.09 - ETA: 1:16:35 - loss: 0.09 - ETA: 1:16:29 - loss: 0.09 - ETA: 1:16:22 - loss: 0.09 - ETA: 1:16:15 - loss: 0.09 - ETA: 1:16:09 - loss: 0.09 - ETA: 1:16:02 - loss: 0.09 - ETA: 1:15:55 - loss: 0.09 - ETA: 1:15:49 - loss: 0.09 - ETA: 1:15:42 - loss: 0.09 - ETA: 1:15:36 - loss: 0.09 - ETA: 1:15:29 - loss: 0.09 - ETA: 1:15:23 - loss: 0.09 - ETA: 1:15:16 - loss: 0.09 - ETA: 1:15:10 - loss: 0.09 - ETA: 1:15:03 - loss: 0.09 - ETA: 1:14:57 - loss: 0.09 - ETA: 1:14:50 - loss: 0.09 - ETA: 1:14:43 - loss: 0.09 - ETA: 1:14:37 - loss: 0.09 - ETA: 1:14:31 - loss: 0.09 - ETA: 1:14:24 - loss: 0.09 - ETA: 1:14:18 - loss: 0.09 - ETA: 1:14:11 - loss: 0.09 - ETA: 1:14:05 - loss: 0.09 - ETA: 1:13:58 - loss: 0.09 - ETA: 1:13:51 - loss: 0.09 - ETA: 1:13:45 - loss: 0.09 - ETA: 1:13:39 - loss: 0.09 - ETA: 1:13:32 - loss: 0.09 - ETA: 1:13:26 - loss: 0.09 - ETA: 1:13:19 - loss: 0.09 - ETA: 1:13:13 - loss: 0.09 - ETA: 1:13:07 - loss: 0.09 - ETA: 1:13:00 - loss: 0.09 - ETA: 1:12:54 - loss: 0.09 - ETA: 1:12:48 - loss: 0.09 - ETA: 1:12:41 - loss: 0.09 - ETA: 1:12:34 - loss: 0.09 - ETA: 1:12:28 - loss: 0.09 - ETA: 1:12:21 - loss: 0.09 - ETA: 1:12:15 - loss: 0.09 - ETA: 1:12:08 - loss: 0.09 - ETA: 1:12:02 - loss: 0.09 - ETA: 1:11:56 - loss: 0.09 - ETA: 1:11:49 - loss: 0.09 - ETA: 1:11:43 - loss: 0.09 - ETA: 1:11:36 - loss: 0.09 - ETA: 1:11:30 - loss: 0.09 - ETA: 1:11:24 - loss: 0.09 - ETA: 1:11:17 - loss: 0.09 - ETA: 1:11:11 - loss: 0.09 - ETA: 1:11:04 - loss: 0.09 - ETA: 1:10:58 - loss: 0.09 - ETA: 1:10:51 - loss: 0.09 - ETA: 1:10:45 - loss: 0.09 - ETA: 1:10:39 - loss: 0.09 - ETA: 1:10:32 - loss: 0.09 - ETA: 1:10:26 - loss: 0.09 - ETA: 1:10:19 - loss: 0.09 - ETA: 1:10:12 - loss: 0.09 - ETA: 1:10:06 - loss: 0.09 - ETA: 1:09:59 - loss: 0.09 - ETA: 1:09:53 - loss: 0.09 - ETA: 1:09:46 - loss: 0.09 - ETA: 1:09:40 - loss: 0.09 - ETA: 1:09:33 - loss: 0.09 - ETA: 1:09:27 - loss: 0.09 - ETA: 1:09:21 - loss: 0.09 - ETA: 1:09:15 - loss: 0.09 - ETA: 1:09:09 - loss: 0.09 - ETA: 1:09:03 - loss: 0.09 - ETA: 1:08:57 - loss: 0.09 - ETA: 1:08:51 - loss: 0.09 - ETA: 1:08:46 - loss: 0.09 - ETA: 1:08:40 - loss: 0.09 - ETA: 1:08:35 - loss: 0.09 - ETA: 1:08:29 - loss: 0.09 - ETA: 1:08:23 - loss: 0.09 - ETA: 1:08:17 - loss: 0.09 - ETA: 1:08:10 - loss: 0.09 - ETA: 1:08:04 - loss: 0.09 - ETA: 1:07:58 - loss: 0.09 - ETA: 1:07:51 - loss: 0.09 - ETA: 1:07:45 - loss: 0.09 - ETA: 1:07:39 - loss: 0.09 - ETA: 1:07:33 - loss: 0.09 - ETA: 1:07:27 - loss: 0.09 - ETA: 1:07:21 - loss: 0.09 - ETA: 1:07:14 - loss: 0.09 - ETA: 1:07:08 - loss: 0.09 - ETA: 1:07:02 - loss: 0.09 - ETA: 1:06:56 - loss: 0.09 - ETA: 1:06:50 - loss: 0.09 - ETA: 1:06:44 - loss: 0.09 - ETA: 1:06:38 - loss: 0.09 - ETA: 1:06:31 - loss: 0.09 - ETA: 1:06:25 - loss: 0.09 - ETA: 1:06:19 - loss: 0.09 - ETA: 1:06:12 - loss: 0.09 - ETA: 1:06:06 - loss: 0.09 - ETA: 1:06:00 - loss: 0.09 - ETA: 1:05:54 - loss: 0.09 - ETA: 1:05:48 - loss: 0.09 - ETA: 1:05:42 - loss: 0.09 - ETA: 1:05:36 - loss: 0.09 - ETA: 1:05:30 - loss: 0.09 - ETA: 1:05:23 - loss: 0.09 - ETA: 1:05:17 - loss: 0.09 - ETA: 1:05:11 - loss: 0.09 - ETA: 1:05:05 - loss: 0.09 - ETA: 1:04:59 - loss: 0.09 - ETA: 1:04:53 - loss: 0.09 - ETA: 1:04:46 - loss: 0.09 - ETA: 1:04:40 - loss: 0.09 - ETA: 1:04:33 - loss: 0.09 - ETA: 1:04:27 - loss: 0.09 - ETA: 1:04:21 - loss: 0.09 - ETA: 1:04:15 - loss: 0.09 - ETA: 1:04:09 - loss: 0.09 - ETA: 1:04:02 - loss: 0.0965131520/154783 [========================>.....] - ETA: 1:03:56 - loss: 0.09 - ETA: 1:03:50 - loss: 0.09 - ETA: 1:03:44 - loss: 0.09 - ETA: 1:03:37 - loss: 0.09 - ETA: 1:03:31 - loss: 0.09 - ETA: 1:03:25 - loss: 0.09 - ETA: 1:03:18 - loss: 0.09 - ETA: 1:03:12 - loss: 0.09 - ETA: 1:03:07 - loss: 0.09 - ETA: 1:03:01 - loss: 0.09 - ETA: 1:02:55 - loss: 0.09 - ETA: 1:02:48 - loss: 0.09 - ETA: 1:02:42 - loss: 0.09 - ETA: 1:02:36 - loss: 0.09 - ETA: 1:02:30 - loss: 0.09 - ETA: 1:02:24 - loss: 0.09 - ETA: 1:02:18 - loss: 0.09 - ETA: 1:02:12 - loss: 0.09 - ETA: 1:02:06 - loss: 0.09 - ETA: 1:01:59 - loss: 0.09 - ETA: 1:01:53 - loss: 0.09 - ETA: 1:01:47 - loss: 0.09 - ETA: 1:01:41 - loss: 0.09 - ETA: 1:01:35 - loss: 0.09 - ETA: 1:01:28 - loss: 0.09 - ETA: 1:01:22 - loss: 0.09 - ETA: 1:01:16 - loss: 0.09 - ETA: 1:01:10 - loss: 0.09 - ETA: 1:01:04 - loss: 0.09 - ETA: 1:00:57 - loss: 0.09 - ETA: 1:00:51 - loss: 0.09 - ETA: 1:00:45 - loss: 0.09 - ETA: 1:00:39 - loss: 0.09 - ETA: 1:00:32 - loss: 0.09 - ETA: 1:00:26 - loss: 0.09 - ETA: 1:00:20 - loss: 0.09 - ETA: 1:00:14 - loss: 0.09 - ETA: 1:00:07 - loss: 0.09 - ETA: 1:00:01 - loss: 0.09 - ETA: 59:55 - loss: 0.0958 - ETA: 59:49 - loss: 0.09 - ETA: 59:43 - loss: 0.09 - ETA: 59:37 - loss: 0.09 - ETA: 59:30 - loss: 0.09 - ETA: 59:24 - loss: 0.09 - ETA: 59:18 - loss: 0.09 - ETA: 59:12 - loss: 0.09 - ETA: 59:05 - loss: 0.09 - ETA: 59:00 - loss: 0.09 - ETA: 58:54 - loss: 0.09 - ETA: 58:49 - loss: 0.09 - ETA: 58:43 - loss: 0.09 - ETA: 58:37 - loss: 0.09 - ETA: 58:31 - loss: 0.09 - ETA: 58:25 - loss: 0.09 - ETA: 58:19 - loss: 0.09 - ETA: 58:13 - loss: 0.09 - ETA: 58:07 - loss: 0.09 - ETA: 58:01 - loss: 0.09 - ETA: 57:55 - loss: 0.09 - ETA: 57:49 - loss: 0.09 - ETA: 57:43 - loss: 0.09 - ETA: 57:37 - loss: 0.09 - ETA: 57:31 - loss: 0.09 - ETA: 57:25 - loss: 0.09 - ETA: 57:19 - loss: 0.09 - ETA: 57:13 - loss: 0.09 - ETA: 57:06 - loss: 0.09 - ETA: 57:01 - loss: 0.09 - ETA: 56:55 - loss: 0.09 - ETA: 56:49 - loss: 0.09 - ETA: 56:43 - loss: 0.09 - ETA: 56:37 - loss: 0.09 - ETA: 56:31 - loss: 0.09 - ETA: 56:24 - loss: 0.09 - ETA: 56:18 - loss: 0.09 - ETA: 56:12 - loss: 0.09 - ETA: 56:06 - loss: 0.09 - ETA: 56:00 - loss: 0.09 - ETA: 55:54 - loss: 0.09 - ETA: 55:48 - loss: 0.09 - ETA: 55:42 - loss: 0.09 - ETA: 55:36 - loss: 0.09 - ETA: 55:31 - loss: 0.09 - ETA: 55:25 - loss: 0.09 - ETA: 55:19 - loss: 0.09 - ETA: 55:13 - loss: 0.09 - ETA: 55:06 - loss: 0.09 - ETA: 55:00 - loss: 0.09 - ETA: 54:54 - loss: 0.09 - ETA: 54:48 - loss: 0.09 - ETA: 54:42 - loss: 0.09 - ETA: 54:36 - loss: 0.09 - ETA: 54:30 - loss: 0.09 - ETA: 54:24 - loss: 0.09 - ETA: 54:18 - loss: 0.09 - ETA: 54:12 - loss: 0.09 - ETA: 54:07 - loss: 0.09 - ETA: 54:01 - loss: 0.09 - ETA: 53:55 - loss: 0.09 - ETA: 53:50 - loss: 0.09 - ETA: 53:44 - loss: 0.09 - ETA: 53:38 - loss: 0.09 - ETA: 53:32 - loss: 0.09 - ETA: 53:27 - loss: 0.09 - ETA: 53:21 - loss: 0.09 - ETA: 53:15 - loss: 0.09 - ETA: 53:10 - loss: 0.09 - ETA: 53:04 - loss: 0.09 - ETA: 52:59 - loss: 0.09 - ETA: 52:53 - loss: 0.09 - ETA: 52:48 - loss: 0.09 - ETA: 52:42 - loss: 0.09 - ETA: 52:36 - loss: 0.09 - ETA: 52:30 - loss: 0.09 - ETA: 52:24 - loss: 0.09 - ETA: 52:18 - loss: 0.09 - ETA: 52:13 - loss: 0.09 - ETA: 52:08 - loss: 0.09 - ETA: 52:02 - loss: 0.09 - ETA: 51:56 - loss: 0.09 - ETA: 51:51 - loss: 0.09 - ETA: 51:45 - loss: 0.09 - ETA: 51:39 - loss: 0.09 - ETA: 51:33 - loss: 0.09 - ETA: 51:27 - loss: 0.09 - ETA: 51:21 - loss: 0.09 - ETA: 51:15 - loss: 0.09 - ETA: 51:09 - loss: 0.09 - ETA: 51:03 - loss: 0.09 - ETA: 50:57 - loss: 0.09 - ETA: 50:51 - loss: 0.09 - ETA: 50:45 - loss: 0.09 - ETA: 50:39 - loss: 0.09 - ETA: 50:33 - loss: 0.09 - ETA: 50:28 - loss: 0.09 - ETA: 50:23 - loss: 0.09 - ETA: 50:17 - loss: 0.09 - ETA: 50:11 - loss: 0.09 - ETA: 50:06 - loss: 0.09 - ETA: 50:00 - loss: 0.09 - ETA: 49:55 - loss: 0.09 - ETA: 49:49 - loss: 0.09 - ETA: 49:44 - loss: 0.09 - ETA: 49:38 - loss: 0.09 - ETA: 49:33 - loss: 0.09 - ETA: 49:27 - loss: 0.09 - ETA: 49:21 - loss: 0.09 - ETA: 49:15 - loss: 0.09 - ETA: 49:09 - loss: 0.09 - ETA: 49:04 - loss: 0.09 - ETA: 48:57 - loss: 0.09 - ETA: 48:52 - loss: 0.09 - ETA: 48:46 - loss: 0.09 - ETA: 48:41 - loss: 0.09 - ETA: 48:35 - loss: 0.09 - ETA: 48:30 - loss: 0.09 - ETA: 48:24 - loss: 0.09 - ETA: 48:18 - loss: 0.09 - ETA: 48:13 - loss: 0.09 - ETA: 48:07 - loss: 0.09 - ETA: 48:02 - loss: 0.09 - ETA: 47:56 - loss: 0.09 - ETA: 47:50 - loss: 0.09 - ETA: 47:45 - loss: 0.09 - ETA: 47:39 - loss: 0.09 - ETA: 47:33 - loss: 0.09 - ETA: 47:27 - loss: 0.09 - ETA: 47:21 - loss: 0.09 - ETA: 47:16 - loss: 0.09 - ETA: 47:11 - loss: 0.09 - ETA: 47:06 - loss: 0.09 - ETA: 47:00 - loss: 0.09 - ETA: 46:55 - loss: 0.09 - ETA: 46:50 - loss: 0.09 - ETA: 46:44 - loss: 0.09 - ETA: 46:39 - loss: 0.09 - ETA: 46:33 - loss: 0.09 - ETA: 46:27 - loss: 0.09 - ETA: 46:22 - loss: 0.09 - ETA: 46:16 - loss: 0.09 - ETA: 46:11 - loss: 0.09 - ETA: 46:05 - loss: 0.09 - ETA: 45:59 - loss: 0.09 - ETA: 45:54 - loss: 0.09 - ETA: 45:48 - loss: 0.09 - ETA: 45:43 - loss: 0.09 - ETA: 45:37 - loss: 0.09 - ETA: 45:32 - loss: 0.09 - ETA: 45:26 - loss: 0.09 - ETA: 45:21 - loss: 0.09 - ETA: 45:15 - loss: 0.09 - ETA: 45:09 - loss: 0.09 - ETA: 45:03 - loss: 0.09 - ETA: 44:57 - loss: 0.09 - ETA: 44:52 - loss: 0.09 - ETA: 44:46 - loss: 0.09 - ETA: 44:41 - loss: 0.09 - ETA: 44:35 - loss: 0.09 - ETA: 44:29 - loss: 0.09 - ETA: 44:23 - loss: 0.09 - ETA: 44:17 - loss: 0.09 - ETA: 44:11 - loss: 0.09 - ETA: 44:05 - loss: 0.09 - ETA: 43:59 - loss: 0.09 - ETA: 43:54 - loss: 0.09 - ETA: 43:48 - loss: 0.09 - ETA: 43:43 - loss: 0.09 - ETA: 43:37 - loss: 0.09 - ETA: 43:31 - loss: 0.09 - ETA: 43:26 - loss: 0.09 - ETA: 43:20 - loss: 0.09 - ETA: 43:14 - loss: 0.09 - ETA: 43:09 - loss: 0.09 - ETA: 43:03 - loss: 0.09 - ETA: 42:57 - loss: 0.09 - ETA: 42:51 - loss: 0.09 - ETA: 42:46 - loss: 0.09 - ETA: 42:40 - loss: 0.09 - ETA: 42:35 - loss: 0.09 - ETA: 42:29 - loss: 0.09 - ETA: 42:23 - loss: 0.09 - ETA: 42:18 - loss: 0.09 - ETA: 42:12 - loss: 0.09 - ETA: 42:07 - loss: 0.09 - ETA: 42:01 - loss: 0.09 - ETA: 41:56 - loss: 0.09 - ETA: 41:50 - loss: 0.09 - ETA: 41:44 - loss: 0.09 - ETA: 41:38 - loss: 0.09 - ETA: 41:32 - loss: 0.09 - ETA: 41:27 - loss: 0.09 - ETA: 41:21 - loss: 0.09 - ETA: 41:15 - loss: 0.09 - ETA: 41:09 - loss: 0.09 - ETA: 41:04 - loss: 0.09 - ETA: 40:58 - loss: 0.09 - ETA: 40:52 - loss: 0.09 - ETA: 40:46 - loss: 0.09 - ETA: 40:41 - loss: 0.09 - ETA: 40:35 - loss: 0.09 - ETA: 40:29 - loss: 0.09 - ETA: 40:23 - loss: 0.09 - ETA: 40:18 - loss: 0.09 - ETA: 40:12 - loss: 0.09 - ETA: 40:06 - loss: 0.09 - ETA: 40:01 - loss: 0.09 - ETA: 39:55 - loss: 0.09 - ETA: 39:49 - loss: 0.09 - ETA: 39:44 - loss: 0.09 - ETA: 39:38 - loss: 0.09 - ETA: 39:33 - loss: 0.09 - ETA: 39:27 - loss: 0.09 - ETA: 39:21 - loss: 0.09 - ETA: 39:16 - loss: 0.09 - ETA: 39:10 - loss: 0.09 - ETA: 39:04 - loss: 0.09 - ETA: 38:58 - loss: 0.09 - ETA: 38:53 - loss: 0.09 - ETA: 38:47 - loss: 0.09 - ETA: 38:41 - loss: 0.09 - ETA: 38:35 - loss: 0.09 - ETA: 38:30 - loss: 0.09 - ETA: 38:24 - loss: 0.09 - ETA: 38:18 - loss: 0.09 - ETA: 38:13 - loss: 0.09 - ETA: 38:07 - loss: 0.09 - ETA: 38:01 - loss: 0.09 - ETA: 37:56 - loss: 0.09 - ETA: 37:50 - loss: 0.09 - ETA: 37:44 - loss: 0.09 - ETA: 37:38 - loss: 0.09 - ETA: 37:33 - loss: 0.09 - ETA: 37:27 - loss: 0.09 - ETA: 37:22 - loss: 0.09 - ETA: 37:16 - loss: 0.09 - ETA: 37:10 - loss: 0.09 - ETA: 37:05 - loss: 0.09 - ETA: 36:59 - loss: 0.09 - ETA: 36:53 - loss: 0.09 - ETA: 36:47 - loss: 0.09 - ETA: 36:42 - loss: 0.09 - ETA: 36:36 - loss: 0.09 - ETA: 36:30 - loss: 0.09 - ETA: 36:25 - loss: 0.09 - ETA: 36:19 - loss: 0.09 - ETA: 36:13 - loss: 0.09 - ETA: 36:07 - loss: 0.09 - ETA: 36:01 - loss: 0.09 - ETA: 35:56 - loss: 0.09 - ETA: 35:50 - loss: 0.09 - ETA: 35:45 - loss: 0.09 - ETA: 35:39 - loss: 0.09 - ETA: 35:33 - loss: 0.09 - ETA: 35:27 - loss: 0.09 - ETA: 35:22 - loss: 0.09 - ETA: 35:16 - loss: 0.09 - ETA: 35:11 - loss: 0.09 - ETA: 35:05 - loss: 0.09 - ETA: 34:59 - loss: 0.09 - ETA: 34:54 - loss: 0.09 - ETA: 34:48 - loss: 0.09 - ETA: 34:42 - loss: 0.09 - ETA: 34:37 - loss: 0.09 - ETA: 34:31 - loss: 0.09 - ETA: 34:25 - loss: 0.09 - ETA: 34:19 - loss: 0.09 - ETA: 34:14 - loss: 0.09 - ETA: 34:08 - loss: 0.09 - ETA: 34:03 - loss: 0.09 - ETA: 33:57 - loss: 0.0916151616/154783 [============================>.] - ETA: 33:52 - loss: 0.09 - ETA: 33:46 - loss: 0.09 - ETA: 33:41 - loss: 0.09 - ETA: 33:35 - loss: 0.09 - ETA: 33:30 - loss: 0.09 - ETA: 33:24 - loss: 0.09 - ETA: 33:18 - loss: 0.09 - ETA: 33:13 - loss: 0.09 - ETA: 33:07 - loss: 0.09 - ETA: 33:01 - loss: 0.09 - ETA: 32:56 - loss: 0.09 - ETA: 32:50 - loss: 0.09 - ETA: 32:44 - loss: 0.09 - ETA: 32:38 - loss: 0.09 - ETA: 32:33 - loss: 0.09 - ETA: 32:27 - loss: 0.09 - ETA: 32:21 - loss: 0.09 - ETA: 32:16 - loss: 0.09 - ETA: 32:10 - loss: 0.09 - ETA: 32:04 - loss: 0.09 - ETA: 31:59 - loss: 0.09 - ETA: 31:53 - loss: 0.09 - ETA: 31:47 - loss: 0.09 - ETA: 31:42 - loss: 0.09 - ETA: 31:36 - loss: 0.09 - ETA: 31:30 - loss: 0.09 - ETA: 31:25 - loss: 0.09 - ETA: 31:19 - loss: 0.09 - ETA: 31:13 - loss: 0.09 - ETA: 31:08 - loss: 0.09 - ETA: 31:02 - loss: 0.09 - ETA: 30:56 - loss: 0.09 - ETA: 30:51 - loss: 0.09 - ETA: 30:45 - loss: 0.09 - ETA: 30:39 - loss: 0.09 - ETA: 30:33 - loss: 0.09 - ETA: 30:28 - loss: 0.09 - ETA: 30:22 - loss: 0.09 - ETA: 30:16 - loss: 0.09 - ETA: 30:11 - loss: 0.09 - ETA: 30:05 - loss: 0.09 - ETA: 29:59 - loss: 0.09 - ETA: 29:54 - loss: 0.09 - ETA: 29:48 - loss: 0.09 - ETA: 29:43 - loss: 0.09 - ETA: 29:38 - loss: 0.09 - ETA: 29:32 - loss: 0.09 - ETA: 29:27 - loss: 0.09 - ETA: 29:21 - loss: 0.09 - ETA: 29:15 - loss: 0.09 - ETA: 29:10 - loss: 0.09 - ETA: 29:04 - loss: 0.09 - ETA: 28:59 - loss: 0.09 - ETA: 28:53 - loss: 0.09 - ETA: 28:48 - loss: 0.09 - ETA: 28:42 - loss: 0.09 - ETA: 28:36 - loss: 0.09 - ETA: 28:30 - loss: 0.09 - ETA: 28:25 - loss: 0.09 - ETA: 28:19 - loss: 0.09 - ETA: 28:14 - loss: 0.09 - ETA: 28:08 - loss: 0.09 - ETA: 28:02 - loss: 0.09 - ETA: 27:57 - loss: 0.09 - ETA: 27:51 - loss: 0.09 - ETA: 27:45 - loss: 0.09 - ETA: 27:39 - loss: 0.09 - ETA: 27:34 - loss: 0.09 - ETA: 27:28 - loss: 0.09 - ETA: 27:22 - loss: 0.09 - ETA: 27:16 - loss: 0.09 - ETA: 27:11 - loss: 0.09 - ETA: 27:05 - loss: 0.09 - ETA: 26:59 - loss: 0.09 - ETA: 26:53 - loss: 0.09 - ETA: 26:47 - loss: 0.09 - ETA: 26:42 - loss: 0.09 - ETA: 26:36 - loss: 0.09 - ETA: 26:30 - loss: 0.09 - ETA: 26:24 - loss: 0.09 - ETA: 26:18 - loss: 0.09 - ETA: 26:12 - loss: 0.09 - ETA: 26:07 - loss: 0.09 - ETA: 26:01 - loss: 0.09 - ETA: 25:55 - loss: 0.09 - ETA: 25:49 - loss: 0.09 - ETA: 25:43 - loss: 0.09 - ETA: 25:38 - loss: 0.09 - ETA: 25:32 - loss: 0.09 - ETA: 25:26 - loss: 0.09 - ETA: 25:20 - loss: 0.09 - ETA: 25:15 - loss: 0.09 - ETA: 25:09 - loss: 0.09 - ETA: 25:03 - loss: 0.09 - ETA: 24:58 - loss: 0.09 - ETA: 24:52 - loss: 0.09 - ETA: 24:46 - loss: 0.09 - ETA: 24:40 - loss: 0.09 - ETA: 24:35 - loss: 0.09 - ETA: 24:29 - loss: 0.09 - ETA: 24:23 - loss: 0.09 - ETA: 24:18 - loss: 0.09 - ETA: 24:12 - loss: 0.09 - ETA: 24:06 - loss: 0.09 - ETA: 24:01 - loss: 0.09 - ETA: 23:55 - loss: 0.09 - ETA: 23:49 - loss: 0.09 - ETA: 23:43 - loss: 0.09 - ETA: 23:38 - loss: 0.09 - ETA: 23:32 - loss: 0.09 - ETA: 23:26 - loss: 0.09 - ETA: 23:21 - loss: 0.09 - ETA: 23:15 - loss: 0.09 - ETA: 23:09 - loss: 0.09 - ETA: 23:03 - loss: 0.09 - ETA: 22:58 - loss: 0.09 - ETA: 22:52 - loss: 0.09 - ETA: 22:46 - loss: 0.09 - ETA: 22:40 - loss: 0.09 - ETA: 22:35 - loss: 0.09 - ETA: 22:29 - loss: 0.09 - ETA: 22:23 - loss: 0.08 - ETA: 22:18 - loss: 0.09 - ETA: 22:12 - loss: 0.08 - ETA: 22:06 - loss: 0.08 - ETA: 22:00 - loss: 0.08 - ETA: 21:55 - loss: 0.08 - ETA: 21:49 - loss: 0.08 - ETA: 21:43 - loss: 0.08 - ETA: 21:38 - loss: 0.08 - ETA: 21:32 - loss: 0.08 - ETA: 21:26 - loss: 0.08 - ETA: 21:21 - loss: 0.08 - ETA: 21:15 - loss: 0.08 - ETA: 21:09 - loss: 0.08 - ETA: 21:04 - loss: 0.08 - ETA: 20:58 - loss: 0.08 - ETA: 20:52 - loss: 0.08 - ETA: 20:46 - loss: 0.08 - ETA: 20:41 - loss: 0.08 - ETA: 20:35 - loss: 0.08 - ETA: 20:30 - loss: 0.08 - ETA: 20:25 - loss: 0.08 - ETA: 20:19 - loss: 0.08 - ETA: 20:13 - loss: 0.08 - ETA: 20:08 - loss: 0.08 - ETA: 20:02 - loss: 0.08 - ETA: 19:56 - loss: 0.08 - ETA: 19:51 - loss: 0.08 - ETA: 19:45 - loss: 0.08 - ETA: 19:40 - loss: 0.08 - ETA: 19:34 - loss: 0.08 - ETA: 19:28 - loss: 0.08 - ETA: 19:23 - loss: 0.08 - ETA: 19:17 - loss: 0.08 - ETA: 19:12 - loss: 0.08 - ETA: 19:06 - loss: 0.08 - ETA: 19:01 - loss: 0.08 - ETA: 18:55 - loss: 0.08 - ETA: 18:50 - loss: 0.08 - ETA: 18:44 - loss: 0.08 - ETA: 18:39 - loss: 0.08 - ETA: 18:33 - loss: 0.08 - ETA: 18:27 - loss: 0.08 - ETA: 18:22 - loss: 0.08 - ETA: 18:16 - loss: 0.08 - ETA: 18:11 - loss: 0.08 - ETA: 18:05 - loss: 0.08 - ETA: 17:59 - loss: 0.08 - ETA: 17:54 - loss: 0.08 - ETA: 17:48 - loss: 0.08 - ETA: 17:43 - loss: 0.08 - ETA: 17:37 - loss: 0.08 - ETA: 17:32 - loss: 0.08 - ETA: 17:26 - loss: 0.08 - ETA: 17:21 - loss: 0.08 - ETA: 17:15 - loss: 0.08 - ETA: 17:10 - loss: 0.08 - ETA: 17:04 - loss: 0.08 - ETA: 16:58 - loss: 0.08 - ETA: 16:53 - loss: 0.08 - ETA: 16:47 - loss: 0.08 - ETA: 16:41 - loss: 0.08 - ETA: 16:36 - loss: 0.08 - ETA: 16:30 - loss: 0.08 - ETA: 16:25 - loss: 0.08 - ETA: 16:19 - loss: 0.08 - ETA: 16:14 - loss: 0.08 - ETA: 16:08 - loss: 0.08 - ETA: 16:03 - loss: 0.08 - ETA: 15:57 - loss: 0.08 - ETA: 15:52 - loss: 0.08 - ETA: 15:46 - loss: 0.08 - ETA: 15:41 - loss: 0.08 - ETA: 15:35 - loss: 0.08 - ETA: 15:30 - loss: 0.08 - ETA: 15:24 - loss: 0.08 - ETA: 15:19 - loss: 0.08 - ETA: 15:13 - loss: 0.08 - ETA: 15:08 - loss: 0.08 - ETA: 15:02 - loss: 0.08 - ETA: 14:57 - loss: 0.08 - ETA: 14:51 - loss: 0.08 - ETA: 14:45 - loss: 0.08 - ETA: 14:40 - loss: 0.08 - ETA: 14:34 - loss: 0.08 - ETA: 14:29 - loss: 0.08 - ETA: 14:23 - loss: 0.08 - ETA: 14:18 - loss: 0.08 - ETA: 14:12 - loss: 0.08 - ETA: 14:06 - loss: 0.08 - ETA: 14:01 - loss: 0.08 - ETA: 13:55 - loss: 0.08 - ETA: 13:50 - loss: 0.08 - ETA: 13:44 - loss: 0.08 - ETA: 13:39 - loss: 0.08 - ETA: 13:33 - loss: 0.08 - ETA: 13:28 - loss: 0.08 - ETA: 13:22 - loss: 0.08 - ETA: 13:17 - loss: 0.08 - ETA: 13:11 - loss: 0.08 - ETA: 13:05 - loss: 0.08 - ETA: 13:00 - loss: 0.08 - ETA: 12:54 - loss: 0.08 - ETA: 12:49 - loss: 0.08 - ETA: 12:43 - loss: 0.08 - ETA: 12:38 - loss: 0.08 - ETA: 12:32 - loss: 0.08 - ETA: 12:27 - loss: 0.08 - ETA: 12:21 - loss: 0.08 - ETA: 12:16 - loss: 0.08 - ETA: 12:10 - loss: 0.08 - ETA: 12:04 - loss: 0.08 - ETA: 11:59 - loss: 0.08 - ETA: 11:53 - loss: 0.08 - ETA: 11:48 - loss: 0.08 - ETA: 11:42 - loss: 0.08 - ETA: 11:37 - loss: 0.08 - ETA: 11:31 - loss: 0.08 - ETA: 11:26 - loss: 0.08 - ETA: 11:20 - loss: 0.08 - ETA: 11:14 - loss: 0.08 - ETA: 11:09 - loss: 0.08 - ETA: 11:03 - loss: 0.08 - ETA: 10:58 - loss: 0.08 - ETA: 10:52 - loss: 0.08 - ETA: 10:46 - loss: 0.08 - ETA: 10:41 - loss: 0.08 - ETA: 10:35 - loss: 0.08 - ETA: 10:30 - loss: 0.08 - ETA: 10:24 - loss: 0.08 - ETA: 10:19 - loss: 0.08 - ETA: 10:13 - loss: 0.08 - ETA: 10:08 - loss: 0.08 - ETA: 10:02 - loss: 0.08 - ETA: 9:56 - loss: 0.0884 - ETA: 9:51 - loss: 0.088 - ETA: 9:45 - loss: 0.088 - ETA: 9:40 - loss: 0.088 - ETA: 9:34 - loss: 0.088 - ETA: 9:29 - loss: 0.088 - ETA: 9:23 - loss: 0.088 - ETA: 9:18 - loss: 0.088 - ETA: 9:12 - loss: 0.088 - ETA: 9:06 - loss: 0.088 - ETA: 9:01 - loss: 0.088 - ETA: 8:55 - loss: 0.088 - ETA: 8:50 - loss: 0.088 - ETA: 8:44 - loss: 0.088 - ETA: 8:39 - loss: 0.088 - ETA: 8:33 - loss: 0.088 - ETA: 8:28 - loss: 0.088 - ETA: 8:22 - loss: 0.088 - ETA: 8:16 - loss: 0.088 - ETA: 8:11 - loss: 0.088 - ETA: 8:05 - loss: 0.088 - ETA: 8:00 - loss: 0.088 - ETA: 7:54 - loss: 0.088 - ETA: 7:49 - loss: 0.088 - ETA: 7:43 - loss: 0.088 - ETA: 7:37 - loss: 0.088 - ETA: 7:32 - loss: 0.088 - ETA: 7:26 - loss: 0.088 - ETA: 7:21 - loss: 0.088 - ETA: 7:15 - loss: 0.088 - ETA: 7:10 - loss: 0.088 - ETA: 7:04 - loss: 0.088 - ETA: 6:58 - loss: 0.088 - ETA: 6:53 - loss: 0.088 - ETA: 6:47 - loss: 0.088 - ETA: 6:42 - loss: 0.088 - ETA: 6:36 - loss: 0.088 - ETA: 6:31 - loss: 0.088 - ETA: 6:25 - loss: 0.088 - ETA: 6:19 - loss: 0.088 - ETA: 6:14 - loss: 0.088 - ETA: 6:08 - loss: 0.088 - ETA: 6:03 - loss: 0.088 - ETA: 5:57 - loss: 0.088 - ETA: 5:52 - loss: 0.088 - ETA: 5:46 - loss: 0.088 - ETA: 5:41 - loss: 0.088 - ETA: 5:35 - loss: 0.088 - ETA: 5:29 - loss: 0.088 - ETA: 5:24 - loss: 0.088 - ETA: 5:18 - loss: 0.088 - ETA: 5:13 - loss: 0.088 - ETA: 5:07 - loss: 0.088 - ETA: 5:02 - loss: 0.088 - ETA: 4:56 - loss: 0.087 - ETA: 4:50 - loss: 0.087 - ETA: 4:45 - loss: 0.087 - ETA: 4:39 - loss: 0.087 - ETA: 4:34 - loss: 0.0879154783/154783 [==============================] - ETA: 4:28 - loss: 0.087 - ETA: 4:23 - loss: 0.087 - ETA: 4:17 - loss: 0.087 - ETA: 4:12 - loss: 0.087 - ETA: 4:06 - loss: 0.087 - ETA: 4:00 - loss: 0.087 - ETA: 3:55 - loss: 0.087 - ETA: 3:49 - loss: 0.087 - ETA: 3:44 - loss: 0.087 - ETA: 3:38 - loss: 0.087 - ETA: 3:33 - loss: 0.087 - ETA: 3:27 - loss: 0.087 - ETA: 3:22 - loss: 0.087 - ETA: 3:16 - loss: 0.087 - ETA: 3:10 - loss: 0.087 - ETA: 3:05 - loss: 0.087 - ETA: 2:59 - loss: 0.087 - ETA: 2:54 - loss: 0.087 - ETA: 2:48 - loss: 0.087 - ETA: 2:43 - loss: 0.087 - ETA: 2:37 - loss: 0.087 - ETA: 2:32 - loss: 0.087 - ETA: 2:26 - loss: 0.087 - ETA: 2:21 - loss: 0.087 - ETA: 2:15 - loss: 0.087 - ETA: 2:09 - loss: 0.087 - ETA: 2:04 - loss: 0.087 - ETA: 1:58 - loss: 0.087 - ETA: 1:53 - loss: 0.087 - ETA: 1:47 - loss: 0.087 - ETA: 1:42 - loss: 0.087 - ETA: 1:36 - loss: 0.087 - ETA: 1:31 - loss: 0.087 - ETA: 1:25 - loss: 0.087 - ETA: 1:20 - loss: 0.087 - ETA: 1:14 - loss: 0.087 - ETA: 1:09 - loss: 0.087 - ETA: 1:03 - loss: 0.087 - ETA: 57s - loss: 0.087 - ETA: 52s - loss: 0.08 - ETA: 46s - loss: 0.08 - ETA: 41s - loss: 0.08 - ETA: 35s - loss: 0.08 - ETA: 30s - loss: 0.08 - ETA: 24s - loss: 0.08 - ETA: 19s - loss: 0.08 - ETA: 13s - loss: 0.08 - ETA: 8s - loss: 0.0875 - ETA: 2s - loss: 0.087 - 13481s 87ms/step - loss: 0.0875 - val_loss: 0.0601\n",
      "Epoch end 1\n",
      " - AUC - improved from 0.00000 to 0.95649\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n",
    "# Set variables\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "\n",
    "# Set early stopping\n",
    "early_stop = EarlyStopping(monitor=\"roc_auc_val\", mode=\"max\", patience=2)\n",
    "                                                    \n",
    "# Train\n",
    "graph = model.fit(X, y, batch_size=batch_size, epochs=epochs,\n",
    "                  validation_data=(X_val, y_val), callbacks=[RocAuc, early_stop],\n",
    "                  verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFgeJmZll+f8aBEylLZKrCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x212dccbc400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Visualize history of loss\n",
    "plt.plot(graph.history['loss'])\n",
    "plt.plot(graph.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best weights and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(processed_X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle competition submission format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "sample_submission[list_classes] = predictions\n",
    "sample_submission.to_csv(\"submission3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App prediction\n",
    "An app pipeline that can be put into production for toxic comment classification. It will take in a string and return the odds that it is any one of the toxic classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity levels for 'go jump off a bridge jerk':\n",
      "Toxic:         82%\n",
      "Severe Toxic:  4%\n",
      "Obscene:       59%\n",
      "Threat:        0%\n",
      "Insult:        58%\n",
      "Identity Hate: 11%\n",
      "\n",
      "Toxicity levels for 'i will kill you':\n",
      "Toxic:         75%\n",
      "Severe Toxic:  11%\n",
      "Obscene:       37%\n",
      "Threat:        33%\n",
      "Insult:        40%\n",
      "Identity Hate: 15%\n",
      "\n",
      "Toxicity levels for 'have a nice day':\n",
      "Toxic:         2%\n",
      "Severe Toxic:  0%\n",
      "Obscene:       0%\n",
      "Threat:        0%\n",
      "Insult:        0%\n",
      "Identity Hate: 0%\n",
      "\n",
      "Toxicity levels for 'hola, como estas':\n",
      "Toxic:         22%\n",
      "Severe Toxic:  2%\n",
      "Obscene:       12%\n",
      "Threat:        1%\n",
      "Insult:        7%\n",
      "Identity Hate: 3%\n",
      "\n",
      "Toxicity levels for 'hola mierda joder':\n",
      "Toxic:         25%\n",
      "Severe Toxic:  0%\n",
      "Obscene:       6%\n",
      "Threat:        1%\n",
      "Insult:        10%\n",
      "Identity Hate: 2%\n",
      "\n",
      "Toxicity levels for 'fuck off!!':\n",
      "Toxic:         100%\n",
      "Severe Toxic:  23%\n",
      "Obscene:       99%\n",
      "Threat:        0%\n",
      "Insult:        83%\n",
      "Identity Hate: 2%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def toxicity_level(string):\n",
    "    \"\"\"\n",
    "    Return toxicity probability based on inputed string.\n",
    "    \"\"\"\n",
    "    # Process string\n",
    "    new_string = [string]\n",
    "    new_string = tokenizer.texts_to_sequences(new_string)\n",
    "    new_string = pad_sequences(new_string, maxlen=max_len, padding='post', truncating='post')\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(new_string)\n",
    "    \n",
    "    # Print output\n",
    "    print(\"Toxicity levels for '{}':\".format(string))\n",
    "    print('Toxic:         {:.0%}'.format(prediction[0][0]))\n",
    "    print('Severe Toxic:  {:.0%}'.format(prediction[0][1]))\n",
    "    print('Obscene:       {:.0%}'.format(prediction[0][2]))\n",
    "    print('Threat:        {:.0%}'.format(prediction[0][3]))\n",
    "    print('Insult:        {:.0%}'.format(prediction[0][4]))\n",
    "    print('Identity Hate: {:.0%}'.format(prediction[0][5]))\n",
    "    print()\n",
    "    \n",
    "    return\n",
    "\n",
    "toxicity_level('go jump off a bridge jerk')\n",
    "toxicity_level('i will kill you')\n",
    "toxicity_level('have a nice day')\n",
    "toxicity_level('hola, como estas')\n",
    "toxicity_level('hola mierda joder')\n",
    "toxicity_level('fuck off!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above sample data, it can be seen that the predictions are not much accurate.\n",
    "This model is not able to predict the probability as accurate as CNN with word embeddings.\n",
    "This information is not available on Google's Perspective API model where it can be subcatogerized as a threat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity levels for 'Whats up':\n",
      "Toxic:         31%\n",
      "Severe Toxic:  0%\n",
      "Obscene:       11%\n",
      "Threat:        0%\n",
      "Insult:        9%\n",
      "Identity Hate: 0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toxicity_level('Whats up')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same data on Google's Perspective API gives a toxicity level of 5% while the above model give a toxicity level of 31%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCES\n",
    "[[1] https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge#description](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge#description)\n",
    "<br>\n",
    "[[2] https://motherboard.vice.com/en_us/article/qvvv3p/googles-anti-bullying-ai-mistakes-civility-for-decency](https://motherboard.vice.com/en_us/article/qvvv3p/googles-anti-bullying-ai-mistakes-civility-for-decency)\n",
    "<br>\n",
    "[[3] http://colah.github.io/posts/2015-08-Understanding-LSTMs/](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "<br>\n",
    "[[4] http://nymag.com/selectall/2017/02/google-introduces-perspective-a-tool-for-toxic-comments.html](http://nymag.com/selectall/2017/02/google-introduces-perspective-a-tool-for-toxic-comments.html)\n",
    "<br>\n",
    "[[5] https://web.stanford.edu/class/cs224n/reports/2762092.pdf](https://web.stanford.edu/class/cs224n/reports/2762092.pdf)\n",
    "<br>\n",
    "[[6] https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras](https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras)\n",
    "<br>\n",
    "[[7] https://datascience.stackexchange.com/questions/11619/rnn-vs-cnn-at-a-high-level](https://datascience.stackexchange.com/questions/11619/rnn-vs-cnn-at-a-high-level)\n",
    "<br>\n",
    "[[8] https://www.depends-on-the-definition.com/classify-toxic-comments-on-wikipedia/](https://www.depends-on-the-definition.com/classify-toxic-comments-on-wikipedia/)\n",
    "<br>\n",
    "[[9] http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)\n",
    "<br>\n",
    "[[10] http://web.stanford.edu/class/cs224n/reports/6838795.pdf](http://web.stanford.edu/class/cs224n/reports/6838795.pdf)\n",
    "<br>\n",
    "[[11] http://dsbyprateekg.blogspot.com/2017/12/can-you-build-model-to-predict-toxic.html](http://dsbyprateekg.blogspot.com/2017/12/can-you-build-model-to-predict-toxic.html)\n",
    "<br>\n",
    "[[12] https://arxiv.org/pdf/1802.09957.pdf](https://arxiv.org/pdf/1802.09957.pdf)\n",
    "<br>\n",
    "[[13] http://web.stanford.edu/class/cs224n/reports/6909170.pdf](http://web.stanford.edu/class/cs224n/reports/6909170.pdf)\n",
    "<br>\n",
    "[[14] http://web.stanford.edu/class/cs224n/reports/6838601.pdf](http://web.stanford.edu/class/cs224n/reports/6838601.pdf)\n",
    "<br>\n",
    "[[15] http://web.stanford.edu/class/cs224n/reports.html](http://web.stanford.edu/class/cs224n/reports.html)\n",
    "<br>\n",
    "[[16] https://medium.com/@srjoglekar246/first-time-with-kaggle-a-convnet-to-classify-toxic-comments-with-keras-ef84b6d18328](https://medium.com/@srjoglekar246/first-time-with-kaggle-a-convnet-to-classify-toxic-comments-with-keras-ef84b6d18328)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "The text in the document by \"Meven DCunha, Neha Bhangale\" is licensed under CC BY 3.0 https://creativecommons.org/licenses/by/3.0/us/\n",
    "\n",
    "The code in the document by <Author(s)> is licensed under the MIT License https://opensource.org/licenses/MIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
